{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f3bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = 'none'\n",
    "network = 'convnext_xlarge_384_in22ft1k'\n",
    "dataset = 'office_home'\n",
    "source = 'Real'\n",
    "target = 'Clipart'\n",
    "num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe7cf195",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_features_path = 'feature_weights/{}_{}_{}_{}.pt'.format(augmentation, network, dataset, source)\n",
    "target_features_path = 'feature_weights/{}_{}_{}_{}.pt'.format(augmentation, network, dataset, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09e41160",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_image_list_file_path = 'data/{}/labeled_source_images_{}.txt'.format(dataset, source)\n",
    "val_target_image_list_file_path = 'data/{}/validation_target_images_{}_3.txt'.format(dataset, target)\n",
    "unlabeled_target_image_list_file_path = 'data/{}/unlabeled_target_images_{}_{}.txt'.format(dataset, target, num)\n",
    "labeled_target_image_list_file_path = 'data/{}/labeled_target_images_{}_{}.txt'.format(dataset, target, num)\n",
    "source_unique_image_list_path = 'data/{}/unique_image_paths_{}.txt'.format(dataset, source)\n",
    "target_unique_image_list_path = 'data/{}/unique_image_paths_{}.txt'.format(dataset, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1391f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = target_features_path\n",
    "image_list_file_path = val_target_image_list_file_path\n",
    "unique_image_list_path = target_unique_image_list_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66267ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_fromlist(image_list):\n",
    "    # print(\"image_list\", image_list)\n",
    "    with open(image_list) as f:\n",
    "        image_index = [x.split(' ')[0] for x in f.readlines()]\n",
    "    with open(image_list) as f:\n",
    "        label_list = []\n",
    "        selected_list = []\n",
    "        for ind, x in enumerate(f.readlines()):\n",
    "            label = x.split(' ')[1].strip()\n",
    "            label_list.append(int(label))\n",
    "            selected_list.append(ind)\n",
    "        image_index = np.array(image_index)\n",
    "        label_list = np.array(label_list)\n",
    "    image_index = image_index[selected_list]\n",
    "    return image_index, label_list\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d665c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_image_paths, to_labels = make_dataset_fromlist(image_list_file_path)\n",
    "from_image_paths, from_labels = make_dataset_fromlist(unique_image_list_path)\n",
    "assert len(from_image_paths) == len(from_labels)\n",
    "assert len(from_labels) >= len(to_labels)\n",
    "assert all(np.arange(len(from_image_paths)) == from_labels) # check that I didn't make a mistake when calculating the features (make sure they are all in order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71fb6c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_image_paths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88f3cfd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4365,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_image_paths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14686a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Clipart/Alarm_Clock/00001.jpg', 'Clipart/Alarm_Clock/00002.jpg',\n",
       "       'Clipart/Alarm_Clock/00003.jpg', ..., 'Clipart/Webcam/00038.jpg',\n",
       "       'Clipart/Webcam/00039.jpg', 'Clipart/Webcam/00040.jpg'],\n",
       "      dtype='<U30')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30a7ee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "f, y = torch.load(features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ec9e4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([195, 2048])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[torch.tensor(mask)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de078415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   4,   20,   21,   82,   88,   95,  138,  142,  178,  205,  238,  267,\n",
       "         278,  317,  349,  381,  413,  466,  482,  507,  510,  550,  551,  572,\n",
       "         618,  625,  667,  694,  743,  764,  786,  821,  868,  877,  885,  910,\n",
       "         915,  965,  968, 1013, 1036, 1042, 1076, 1102, 1106, 1128, 1151, 1155,\n",
       "        1161, 1172, 1178, 1231, 1238, 1239, 1247, 1250, 1258, 1287, 1292, 1310,\n",
       "        1337, 1338, 1345, 1391, 1408, 1415, 1420, 1443, 1483, 1523, 1599, 1605,\n",
       "        1616, 1649, 1669, 1685, 1686, 1708, 1763, 1795, 1803, 1842, 1843, 1850,\n",
       "        1900, 1931, 1932, 1956, 1969, 1994, 2043, 2080, 2085, 2092, 2093, 2107,\n",
       "        2131, 2149, 2167, 2266, 2272, 2283, 2317, 2353, 2383, 2400, 2407, 2432,\n",
       "        2440, 2469, 2481, 2536, 2555, 2587, 2619, 2621, 2651, 2698, 2701, 2716,\n",
       "        2761, 2772, 2776, 2802, 2819, 2821, 2848, 2870, 2922, 2951, 2957, 2962,\n",
       "        3024, 3031, 3049, 3075, 3106, 3123, 3155, 3186, 3189, 3202, 3221, 3225,\n",
       "        3252, 3273, 3274, 3288, 3304, 3332, 3359, 3376, 3413, 3451, 3464, 3492,\n",
       "        3525, 3528, 3539, 3567, 3573, 3584, 3604, 3607, 3630, 3649, 3679, 3682,\n",
       "        3760, 3767, 3776, 3812, 3825, 3843, 3883, 3921, 3950, 3969, 3988, 4013,\n",
       "        4099, 4100, 4101, 4136, 4161, 4164, 4192, 4215, 4266, 4310, 4315, 4318,\n",
       "        4328, 4332, 4351])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[torch.tensor(mask)].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44f49265",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.in1d(from_image_paths, to_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "583d8255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_image_paths[np.in1d(from_image_paths, to_image_paths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "04870758",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorter = np.argsort(from_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e75f88cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = sorter[np.searchsorted(from_image_paths, to_image_paths, sorter=sorter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "024c8623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_image_paths[ind] == to_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "02c2869c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  21,   20,    4,   88,   82,   95,  178,  138,  142,  238,  205,  267,\n",
       "         349,  317,  278,  413,  381,  466,  507,  510,  482,  551,  550,  572,\n",
       "         625,  618,  667,  764,  694,  743,  786,  821,  868,  885,  877,  910,\n",
       "         968,  965,  915, 1042, 1013, 1036, 1102, 1076, 1106, 1155, 1128, 1151,\n",
       "        1172, 1178, 1161, 1231, 1238, 1239, 1258, 1250, 1247, 1287, 1310, 1292,\n",
       "        1337, 1345, 1338, 1408, 1391, 1415, 1420, 1443, 1483, 1599, 1523, 1605,\n",
       "        1669, 1649, 1616, 1685, 1708, 1686, 1803, 1763, 1795, 1842, 1843, 1850,\n",
       "        1900, 1932, 1931, 1969, 1956, 1994, 2080, 2085, 2043, 2107, 2092, 2093,\n",
       "        2167, 2131, 2149, 2266, 2283, 2272, 2317, 2383, 2353, 2400, 2432, 2407,\n",
       "        2440, 2469, 2481, 2536, 2555, 2587, 2619, 2651, 2621, 2698, 2716, 2701,\n",
       "        2772, 2776, 2761, 2802, 2821, 2819, 2870, 2848, 2922, 2962, 2957, 2951,\n",
       "        3049, 3024, 3031, 3106, 3123, 3075, 3155, 3189, 3186, 3221, 3202, 3225,\n",
       "        3252, 3273, 3274, 3304, 3288, 3332, 3413, 3359, 3376, 3492, 3464, 3451,\n",
       "        3525, 3528, 3539, 3584, 3567, 3573, 3607, 3630, 3604, 3682, 3649, 3679,\n",
       "        3760, 3776, 3767, 3812, 3843, 3825, 3988, 3969, 4013, 4099, 4100, 4101,\n",
       "        4136, 4161, 4164, 4192, 4215, 4266, 4318, 4315, 4310, 3950, 3921, 3883,\n",
       "        4351, 4328, 4332])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[ind].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0e0b565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(ind == y[ind].long().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a57005",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(augmentation='none', dataset='office_home', shots=3)\n",
      "convnext_xlarge_384_in22ft1k\n",
      "CORAL alignment ...\n",
      "get_results.py:68: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:240.)\n",
      "  x_s_whitened = torch.matmul(x_s_n, x_s_cov_sqrt_inv.float()) # whiten\n",
      "Train classifier on labeled ...\n",
      "(81.46283030509949, 99.54096674919128, 81.02564215660095)\n",
      "5 ites of self-training ...\n",
      "(83.69304537773132, 98.85241985321045, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(83.76498818397522, 98.85241985321045, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(84.07673835754395, 98.87537360191345, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(83.98081660270691, 98.92127513885498, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(83.78896713256836, 99.01307821273804, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(83.86090993881226, 98.78356456756592, 82.05128312110901)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(94.72196102142334, 99.49506521224976, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.57021856307983, 98.46224188804626, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(95.97077965736389, 98.66880774497986, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(96.0179090499878, 98.71470928192139, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(96.11215591430664, 98.76061081886292, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(95.90009450912476, 98.62290620803833, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(95.92365622520447, 98.82946610450745, 95.38461565971375)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(88.97849321365356, 99.60982203483582, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(91.03942513465881, 98.99013042449951, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(91.21863842010498, 98.9442229270935, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(90.68100452423096, 99.03603196144104, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(90.94982147216797, 99.05898571014404, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(90.59139490127563, 99.08193349838257, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(90.59139490127563, 99.03603196144104, 89.74359035491943)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.46467852592468, 99.75219368934631, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.52186226844788, 99.34669733047485, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.71408128738403, 99.45933818817139, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.54588890075684, 99.34669733047485, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.449782371521, 99.34669733047485, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.40172910690308, 99.45933818817139, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.449782371521, 99.34669733047485, 93.84615421295166)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(79.30455803871155, 99.7296690940857, 80.0000011920929)\n",
      "5 ites of self-training ...\n",
      "(81.87050223350525, 99.2115318775177, 80.51282167434692)\n",
      "5 ites of self-training ...\n",
      "(81.70263767242432, 99.05384182929993, 81.02564215660095)\n",
      "5 ites of self-training ...\n",
      "(81.79855942726135, 99.27911758422852, 80.0000011920929)\n",
      "5 ites of self-training ...\n",
      "(81.918466091156, 99.2115318775177, 80.0000011920929)\n",
      "5 ites of self-training ...\n",
      "(81.94244503974915, 99.2115318775177, 79.48718070983887)\n",
      "5 ites of self-training ...\n",
      "(81.9904088973999, 99.16647672653198, 79.48718070983887)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.91756129264832, 99.77472424507141, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(89.74014520645142, 99.39175248146057, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(89.4713282585144, 99.41428303718567, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(90.00896215438843, 99.52691793441772, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(89.74014520645142, 99.481862783432, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(89.6505355834961, 99.45933818817139, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(89.6505355834961, 99.45933818817139, 89.2307698726654)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(94.10933256149292, 99.62916970252991, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(95.38171291351318, 99.42315220832825, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(95.31102776527405, 99.29954409599304, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(95.47596573829651, 99.29954409599304, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(95.47596573829651, 99.3819534778595, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(95.52308917045593, 99.46435689926147, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(95.47596573829651, 99.5055615901947, 94.35897469520569)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(80.38369417190552, 99.62916970252991, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(82.8777015209198, 99.5055615901947, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(83.04556608200073, 99.58796501159668, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(83.40527415275574, 99.46435689926147, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(83.18945169448853, 99.5055615901947, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(83.16546678543091, 99.5055615901947, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(83.2374095916748, 99.46435689926147, 83.5897445678711)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.91206002235413, 99.62916970252991, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.16146278381348, 99.5055615901947, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.18548941612244, 99.5055615901947, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.18548941612244, 99.46435689926147, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.25756931304932, 99.5055615901947, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.28159594535828, 99.5055615901947, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.28159594535828, 99.5055615901947, 95.38461565971375)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(91.71071648597717, 98.4879732131958, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(93.8010573387146, 97.2737729549408, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(93.94521713256836, 97.06758260726929, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(93.99327039718628, 97.13631272315979, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(94.04132962226868, 97.2050428390503, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(93.87313723564148, 97.38832116127014, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(93.89716386795044, 97.29667901992798, 96.4102566242218)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(87.6344084739685, 98.53379130363464, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(89.7849440574646, 97.8006899356842, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(89.4713282585144, 97.61741161346436, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(89.56093192100525, 97.6632297039032, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(89.51612710952759, 97.64032363891602, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(89.82974886894226, 97.6632297039032, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(89.82974886894226, 97.54868745803833, 89.74359035491943)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.71913170814514, 98.39633703231812, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.72196102142334, 96.74685001373291, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.6041464805603, 96.86139822006226, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.72196102142334, 96.31156921386719, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.72196102142334, 96.5177595615387, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.62770819664001, 96.56357765197754, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.62770819664001, 96.56357765197754, 94.35897469520569)\n",
      "\n",
      "convnext_xlarge_in22ft1k\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(82.35012292861938, 99.58686828613281, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(84.14868116378784, 98.76061081886292, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(84.24460291862488, 98.71470928192139, 84.10256505012512)\n",
      "5 ites of self-training ...\n",
      "(84.31654572486877, 98.89832139015198, 84.10256505012512)\n",
      "5 ites of self-training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84.5563530921936, 98.92127513885498, 84.10256505012512)\n",
      "5 ites of self-training ...\n",
      "(84.38848853111267, 98.99013042449951, 84.10256505012512)\n",
      "5 ites of self-training ...\n",
      "(84.41247344017029, 98.71470928192139, 84.10256505012512)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.92082691192627, 99.58686828613281, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.00471353530884, 98.73766303062439, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(95.05183696746826, 98.85241985321045, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.95758414268494, 98.69175553321838, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.91046071052551, 98.87537360191345, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.79264616966248, 98.87537360191345, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.8868989944458, 98.99013042449951, 94.35897469520569)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(88.08243870735168, 99.65572357177734, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(90.32257795333862, 99.1737425327301, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(90.18816947937012, 98.99013042449951, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(90.09856581687927, 99.21964406967163, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(90.00896215438843, 99.01307821273804, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(89.82974886894226, 98.9442229270935, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(89.9193525314331, 99.03603196144104, 90.76923131942749)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.17635893821716, 99.75219368934631, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.2095160484314, 99.43680763244629, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(93.9211905002594, 99.43680763244629, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.25756931304932, 99.45933818817139, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.18548941612244, 99.52691793441772, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.11340951919556, 99.61702823638916, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.11340951919556, 99.57197308540344, 94.35897469520569)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(80.16786575317383, 99.77472424507141, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(82.90168046951294, 99.25658702850342, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(82.85371661186218, 99.30164217948914, 80.51282167434692)\n",
      "5 ites of self-training ...\n",
      "(83.06954503059387, 99.32417273521423, 81.02564215660095)\n",
      "5 ites of self-training ...\n",
      "(82.8057587146759, 99.27911758422852, 80.51282167434692)\n",
      "5 ites of self-training ...\n",
      "(82.8057587146759, 99.2115318775177, 80.51282167434692)\n",
      "5 ites of self-training ...\n",
      "(82.70983099937439, 99.25658702850342, 80.51282167434692)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.69354915618896, 99.81977939605713, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(88.97849321365356, 99.7071385383606, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(89.06810283660889, 99.59450364112854, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(89.11290168762207, 99.63955879211426, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(89.24731016159058, 99.52691793441772, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(89.29211497306824, 99.61702823638916, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(89.3369197845459, 99.59450364112854, 90.25641083717346)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.35532188415527, 99.62916970252991, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.43920850753784, 99.46435689926147, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.53345537185669, 99.42315220832825, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.74552273750305, 99.34074878692627, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.83977556228638, 99.46435689926147, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.81620788574219, 99.5055615901947, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.83977556228638, 99.54676628112793, 93.33333373069763)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(81.41486644744873, 99.62916970252991, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(84.07673835754395, 99.46435689926147, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(83.76498818397522, 99.46435689926147, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(83.93285274505615, 99.54676628112793, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(83.93285274505615, 99.46435689926147, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(83.57314467430115, 99.46435689926147, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(83.64508748054504, 99.46435689926147, 83.07692408561707)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.5036072731018, 99.62916970252991, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(93.82508397102356, 99.46435689926147, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(93.87313723564148, 99.58796501159668, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(93.84911060333252, 99.54676628112793, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(93.75300407409668, 99.5055615901947, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(93.94521713256836, 99.5055615901947, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(93.89716386795044, 99.5055615901947, 94.87179517745972)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.21528172492981, 98.4879732131958, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(93.9211905002594, 97.22794890403748, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.6809241771698, 97.41122722625732, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(93.89716386795044, 97.29667901992798, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(93.94521713256836, 97.29667901992798, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(93.94521713256836, 97.34249711036682, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(93.94521713256836, 97.45704531669617, 96.4102566242218)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(87.3655915260315, 98.6254334449768, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.97849321365356, 97.7319598197937, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(88.75448107719421, 97.75487184524536, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(88.66487741470337, 97.75487184524536, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(88.66487741470337, 97.59450554847717, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(88.62007260322571, 97.68614172935486, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(88.62007260322571, 97.68614172935486, 90.25641083717346)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.57775545120239, 98.46506714820862, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.36851739883423, 96.63230180740356, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.36851739883423, 96.76976203918457, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.36851739883423, 96.83849215507507, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.36851739883423, 96.58648371696472, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.3213939666748, 96.76976203918457, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.29783225059509, 96.76976203918457, 93.33333373069763)\n",
      "\n",
      "convnext_xlarge_in22k\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(82.1342945098877, 99.60982203483582, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(84.24460291862488, 99.1737425327301, 85.6410264968872)\n",
      "5 ites of self-training ...\n",
      "(84.6282958984375, 99.26554560661316, 84.61538553237915)\n",
      "5 ites of self-training ...\n",
      "(85.01198887825012, 99.28849935531616, 85.6410264968872)\n",
      "5 ites of self-training ...\n",
      "(84.98800992965698, 99.28849935531616, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(84.89208817481995, 99.12784099578857, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(84.89208817481995, 99.1737425327301, 86.15384697914124)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(94.65126991271973, 99.60982203483582, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(95.35815119743347, 99.21964406967163, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.28746604919434, 99.1737425327301, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(95.4052746295929, 99.24259781837463, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(95.38171291351318, 99.26554560661316, 93.33333373069763)\n",
      "5 ites of self-training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95.52308917045593, 99.19669032096863, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(95.47596573829651, 99.24259781837463, 93.33333373069763)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(88.12723755836487, 99.65572357177734, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(89.87455368041992, 99.44915771484375, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(90.14337062835693, 99.44915771484375, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(89.82974886894226, 99.49506521224976, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(89.7849440574646, 99.42620992660522, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(89.74014520645142, 99.47211146354675, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(89.6505355834961, 99.49506521224976, 89.2307698726654)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.63287091255188, 99.81977939605713, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.47380900382996, 99.57197308540344, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.6179747581482, 99.63955879211426, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.76213455200195, 99.63955879211426, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.78616118431091, 99.63955879211426, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.71408128738403, 99.66208338737488, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.69005465507507, 99.61702823638916, 93.84615421295166)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(79.13669347763062, 99.79724884033203, 77.43589878082275)\n",
      "5 ites of self-training ...\n",
      "(82.51798748970032, 99.34669733047485, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(82.733815908432, 99.45933818817139, 80.51282167434692)\n",
      "5 ites of self-training ...\n",
      "(82.75779485702515, 99.41428303718567, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(82.66187310218811, 99.43680763244629, 80.51282167434692)\n",
      "5 ites of self-training ...\n",
      "(82.37410187721252, 99.41428303718567, 80.51282167434692)\n",
      "5 ites of self-training ...\n",
      "(82.39808082580566, 99.41428303718567, 80.51282167434692)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.15591526031494, 99.81977939605713, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.26164603233337, 99.63955879211426, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(88.39605450630188, 99.66208338737488, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(89.15770649909973, 99.68461394309998, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(89.15770649909973, 99.66208338737488, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(88.84408473968506, 99.66208338737488, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(88.88888955116272, 99.7296690940857, 89.2307698726654)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.97832250595093, 99.62916970252991, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.50989365577698, 99.62916970252991, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.48633193969727, 99.62916970252991, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.76908445358276, 99.62916970252991, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.69839930534363, 99.62916970252991, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.79264616966248, 99.62916970252991, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.8868989944458, 99.62916970252991, 92.8205132484436)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(80.8153510093689, 99.62916970252991, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(83.3093523979187, 99.62916970252991, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(83.16546678543091, 99.58796501159668, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(83.3812952041626, 99.58796501159668, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(83.42925906181335, 99.58796501159668, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(83.35731625556946, 99.58796501159668, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(83.33333134651184, 99.62916970252991, 83.07692408561707)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.64776706695557, 99.62916970252991, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.06535625457764, 99.62916970252991, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.2095160484314, 99.62916970252991, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.23354268074036, 99.62916970252991, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(94.30562257766724, 99.62916970252991, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(94.25756931304932, 99.62916970252991, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(94.23354268074036, 99.62916970252991, 95.89743614196777)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(91.68668985366821, 98.67125153541565, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(93.272465467453, 98.09851050376892, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(93.46467852592468, 97.8006899356842, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(93.77703070640564, 97.82360196113586, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.82508397102356, 97.89232611656189, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(93.84911060333252, 97.8694200515747, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.9211905002594, 97.89232611656189, 95.89743614196777)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.55914068222046, 98.67125153541565, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(89.02329802513123, 98.14433455467224, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(88.79928588867188, 97.98396825790405, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(88.70967626571655, 97.98396825790405, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.53046298027039, 97.98396825790405, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(88.66487741470337, 98.0297863483429, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(88.70967626571655, 98.0297863483429, 88.71794939041138)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.81338453292847, 98.60252141952515, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.50989365577698, 97.70905375480652, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.6041464805603, 97.59450554847717, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.67483162879944, 97.52577543258667, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.62770819664001, 97.41122722625732, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.74552273750305, 97.36540913581848, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.72196102142334, 97.52577543258667, 93.84615421295166)\n",
      "\n",
      "swin_large_patch4_window7_224\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(81.48680925369263, 99.56392049789429, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(83.66906642913818, 99.1737425327301, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(83.50120186805725, 99.08193349838257, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(83.2374095916748, 99.1507887840271, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(83.42925906181335, 99.08193349838257, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(83.40527415275574, 99.33440089225769, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(83.42925906181335, 99.10488724708557, 82.56410360336304)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.4495747089386, 99.58686828613281, 91.28205180168152)\n",
      "5 ites of self-training ...\n",
      "(94.34495568275452, 99.03603196144104, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.39207911491394, 99.1737425327301, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.53345537185669, 99.08193349838257, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.46277022361755, 99.03603196144104, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.62770819664001, 99.1737425327301, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.67483162879944, 99.08193349838257, 93.84615421295166)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.73835396766663, 99.63277578353882, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.17204236984253, 99.08193349838257, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(88.12723755836487, 99.10488724708557, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(87.94803023338318, 99.21964406967163, 85.6410264968872)\n",
      "5 ites of self-training ...\n",
      "(87.81362175941467, 99.1507887840271, 85.6410264968872)\n",
      "5 ites of self-training ...\n",
      "(88.12723755836487, 99.19669032096863, 85.6410264968872)\n",
      "5 ites of self-training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87.99282908439636, 99.21964406967163, 85.6410264968872)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.96011328697205, 99.68461394309998, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.28159594535828, 99.57197308540344, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.3296492099762, 99.5043933391571, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.42575573921204, 99.63955879211426, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.30562257766724, 99.54944849014282, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.28159594535828, 99.54944849014282, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.25756931304932, 99.59450364112854, 93.84615421295166)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(80.16786575317383, 99.7296690940857, 78.46153974533081)\n",
      "5 ites of self-training ...\n",
      "(82.5659453868866, 99.25658702850342, 81.02564215660095)\n",
      "5 ites of self-training ...\n",
      "(82.90168046951294, 99.43680763244629, 81.02564215660095)\n",
      "5 ites of self-training ...\n",
      "(83.09352397918701, 99.43680763244629, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(83.14148783683777, 99.25658702850342, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(83.40527415275574, 99.2115318775177, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(83.3812952041626, 99.36922788619995, 82.05128312110901)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(85.88709831237793, 99.79724884033203, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.62007260322571, 99.5043933391571, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(88.44085931777954, 99.59450364112854, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(88.62007260322571, 99.54944849014282, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(88.62007260322571, 99.481862783432, 87.17948794364929)\n",
      "5 ites of self-training ...\n",
      "(88.3512556552887, 99.5043933391571, 87.17948794364929)\n",
      "5 ites of self-training ...\n",
      "(88.30645084381104, 99.481862783432, 87.17948794364929)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.10650324821472, 99.62916970252991, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.08576488494873, 99.5055615901947, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.10933256149292, 99.5055615901947, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.13289427757263, 99.58796501159668, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.08576488494873, 99.5055615901947, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.18001770973206, 99.62916970252991, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.13289427757263, 99.58796501159668, 92.8205132484436)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(80.40767312049866, 99.62916970252991, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(83.28537344932556, 99.5055615901947, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(83.71702432632446, 99.46435689926147, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(83.52518081665039, 99.42315220832825, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(83.76498818397522, 99.5055615901947, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(83.50120186805725, 99.54676628112793, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(83.54915976524353, 99.5055615901947, 83.07692408561707)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.40749478340149, 99.62916970252991, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(93.94521713256836, 99.54676628112793, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.06535625457764, 99.54676628112793, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.37770247459412, 99.58796501159668, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.16146278381348, 99.54676628112793, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.2095160484314, 99.54676628112793, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(94.2095160484314, 99.58796501159668, 95.89743614196777)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(91.90292954444885, 98.64833950996399, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.06535625457764, 97.6632297039032, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.04132962226868, 97.45704531669617, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.06535625457764, 97.57159352302551, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.01729702949524, 97.36540913581848, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.18548941612244, 97.54868745803833, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.13743615150452, 97.31959104537964, 95.89743614196777)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.20071411132812, 98.60252141952515, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(88.30645084381104, 97.96105623245239, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(88.30645084381104, 98.07560443878174, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(88.17204236984253, 98.00687432289124, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(88.21684718132019, 97.96105623245239, 87.17948794364929)\n",
      "5 ites of self-training ...\n",
      "(87.90322542190552, 98.05269241333008, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(87.85842061042786, 98.0297863483429, 86.66666746139526)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(91.61168336868286, 98.57961535453796, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(93.59095096588135, 97.13631272315979, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(93.70876550674438, 97.22794890403748, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(93.87370347976685, 97.15922474861145, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(93.85014176368713, 97.18213081359863, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(93.7323272228241, 97.18213081359863, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(93.68520379066467, 97.15922474861145, 93.33333373069763)\n",
      "\n",
      "swin_large_patch4_window7_224_in22k\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(80.91127276420593, 99.58686828613281, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(83.83693099021912, 99.28849935531616, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(84.14868116378784, 99.3803083896637, 84.10256505012512)\n",
      "5 ites of self-training ...\n",
      "(84.50839519500732, 99.33440089225769, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(84.41247344017029, 99.3803083896637, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(84.48441624641418, 99.31145310401917, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(84.50839519500732, 99.26554560661316, 83.07692408561707)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.54382753372192, 99.60982203483582, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(95.07539868354797, 99.1737425327301, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(95.1225221157074, 99.10488724708557, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(95.14608979225159, 99.19669032096863, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(95.19321322441101, 99.10488724708557, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(95.14608979225159, 99.19669032096863, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(95.14608979225159, 99.12784099578857, 93.84615421295166)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.60394549369812, 99.63277578353882, 85.12820601463318)\n",
      "5 ites of self-training ...\n",
      "(87.99282908439636, 99.3573546409607, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(87.90322542190552, 99.40325617790222, 85.12820601463318)\n",
      "5 ites of self-training ...\n",
      "(88.03763389587402, 99.40325617790222, 84.61538553237915)\n",
      "5 ites of self-training ...\n",
      "(87.99282908439636, 99.40325617790222, 84.61538553237915)\n",
      "5 ites of self-training ...\n",
      "(87.85842061042786, 99.40325617790222, 85.6410264968872)\n",
      "5 ites of self-training ...\n",
      "(87.67921328544617, 99.49506521224976, 85.12820601463318)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.08025240898132, 99.77472424507141, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.64200139045715, 99.68461394309998, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(94.52186226844788, 99.63955879211426, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.56992149353027, 99.68461394309998, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(94.449782371521, 99.68461394309998, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.40172910690308, 99.66208338737488, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.3296492099762, 99.63955879211426, 94.35897469520569)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(79.06475067138672, 99.81977939605713, 78.46153974533081)\n",
      "5 ites of self-training ...\n",
      "(81.96642994880676, 99.5043933391571, 80.51282167434692)\n",
      "5 ites of self-training ...\n",
      "(82.23021626472473, 99.52691793441772, 81.02564215660095)\n",
      "5 ites of self-training ...\n",
      "(82.20623731613159, 99.54944849014282, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(82.30215907096863, 99.5043933391571, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(82.47002363204956, 99.52691793441772, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(82.51798748970032, 99.5043933391571, 81.53846263885498)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.24551892280579, 99.77472424507141, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(88.21684718132019, 99.63955879211426, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(88.62007260322571, 99.66208338737488, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(88.30645084381104, 99.63955879211426, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(88.30645084381104, 99.68461394309998, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(88.03763389587402, 99.63955879211426, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(87.94803023338318, 99.61702823638916, 88.20512890815735)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.45994091033936, 99.62916970252991, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.13289427757263, 99.62916970252991, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.39207911491394, 99.58796501159668, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.46277022361755, 99.62916970252991, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.50989365577698, 99.62916970252991, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.50989365577698, 99.62916970252991, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.50989365577698, 99.62916970252991, 93.84615421295166)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(79.08872961997986, 99.62916970252991, 81.02564215660095)\n",
      "5 ites of self-training ...\n",
      "(82.47002363204956, 99.62916970252991, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(82.92565941810608, 99.58796501159668, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(82.66187310218811, 99.54676628112793, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(82.733815908432, 99.58796501159668, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(82.61390924453735, 99.58796501159668, 84.10256505012512)\n",
      "5 ites of self-training ...\n",
      "(82.54196643829346, 99.58796501159668, 83.5897445678711)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.7438735961914, 99.62916970252991, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.23354268074036, 99.62916970252991, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(94.47380900382996, 99.58796501159668, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.37770247459412, 99.58796501159668, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.35367584228516, 99.58796501159668, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.30562257766724, 99.62916970252991, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(94.30562257766724, 99.62916970252991, 95.89743614196777)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(90.9418523311615, 98.64833950996399, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(93.58481764793396, 98.09851050376892, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.44065189361572, 98.0297863483429, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.560791015625, 98.07560443878174, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(93.560791015625, 98.05269241333008, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(93.560791015625, 98.21305871009827, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(93.5127317905426, 98.00687432289124, 94.87179517745972)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(85.75268983840942, 98.6254334449768, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(87.90322542190552, 98.25887680053711, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(87.72401213645935, 98.30470085144043, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.21684718132019, 98.12142252922058, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(88.21684718132019, 98.07560443878174, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(88.12723755836487, 98.05269241333008, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(87.94803023338318, 98.0297863483429, 88.20512890815735)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(91.63525104522705, 98.67125153541565, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(93.59095096588135, 97.70905375480652, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(93.54382753372192, 97.68614172935486, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(93.21394562721252, 97.54868745803833, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(93.23751330375671, 97.47995734214783, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(93.21394562721252, 97.54868745803833, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(93.28463673591614, 97.59450554847717, 93.33333373069763)\n",
      "\n",
      "swin_large_patch4_window12_384\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(82.51798748970032, 99.56392049789429, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(84.48441624641418, 99.05898571014404, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(84.36450958251953, 99.08193349838257, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(84.48441624641418, 99.05898571014404, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(84.43645238876343, 99.19669032096863, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(84.5563530921936, 99.12784099578857, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(84.67625975608826, 99.10488724708557, 83.07692408561707)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(94.13289427757263, 99.58686828613281, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.05183696746826, 99.05898571014404, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.33458948135376, 99.01307821273804, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.38171291351318, 99.10488724708557, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(95.28746604919434, 99.12784099578857, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(95.35815119743347, 99.10488724708557, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(95.28746604919434, 99.03603196144104, 93.84615421295166)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(87.90322542190552, 99.63277578353882, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.79928588867188, 99.33440089225769, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(88.66487741470337, 99.26554560661316, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(88.97849321365356, 99.31145310401917, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(88.93369436264038, 99.28849935531616, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(88.84408473968506, 99.3573546409607, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(88.84408473968506, 99.28849935531616, 89.74359035491943)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.24843883514404, 99.77472424507141, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.449782371521, 99.54944849014282, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.49783563613892, 99.5043933391571, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.56992149353027, 99.61702823638916, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.52186226844788, 99.61702823638916, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.56992149353027, 99.57197308540344, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.54588890075684, 99.52691793441772, 94.87179517745972)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(80.743408203125, 99.79724884033203, 78.46153974533081)\n",
      "5 ites of self-training ...\n",
      "(82.733815908432, 99.481862783432, 78.97436022758484)\n",
      "5 ites of self-training ...\n",
      "(82.49400854110718, 99.34669733047485, 80.0000011920929)\n",
      "5 ites of self-training ...\n",
      "(82.8777015209198, 99.57197308540344, 80.51282167434692)\n",
      "5 ites of self-training ...\n",
      "(82.94963836669922, 99.41428303718567, 80.51282167434692)\n",
      "5 ites of self-training ...\n",
      "(83.02158117294312, 99.5043933391571, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(82.90168046951294, 99.45933818817139, 81.53846263885498)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.82795763015747, 99.81977939605713, 88.20512890815735)\n",
      "5 ites of self-training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89.3369197845459, 99.68461394309998, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(89.11290168762207, 99.66208338737488, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(89.29211497306824, 99.59450364112854, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(89.38171863555908, 99.57197308540344, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(89.29211497306824, 99.57197308540344, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(89.29211497306824, 99.61702823638916, 90.76923131942749)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.02544593811035, 99.62916970252991, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.34495568275452, 99.54676628112793, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.62770819664001, 99.46435689926147, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.58058476448059, 99.58796501159668, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.6041464805603, 99.54676628112793, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.58058476448059, 99.58796501159668, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.48633193969727, 99.58796501159668, 92.30769276618958)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(81.03117346763611, 99.62916970252991, 80.0000011920929)\n",
      "5 ites of self-training ...\n",
      "(84.10072326660156, 99.54676628112793, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(84.22062397003174, 99.54676628112793, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(84.29256677627563, 99.5055615901947, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(84.0527594089508, 99.58796501159668, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(83.95683765411377, 99.58796501159668, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(83.93285274505615, 99.58796501159668, 82.56410360336304)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.76790022850037, 99.62916970252991, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.06535625457764, 99.62916970252991, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.13743615150452, 99.58796501159668, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(94.06535625457764, 99.62916970252991, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.0893828868866, 99.62916970252991, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.0893828868866, 99.62916970252991, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.11340951919556, 99.62916970252991, 94.87179517745972)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.35944151878357, 98.57961535453796, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(93.96924376487732, 97.64032363891602, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.96924376487732, 97.59450554847717, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(94.2095160484314, 97.54868745803833, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.18548941612244, 97.43413925170898, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.13743615150452, 97.82360196113586, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(93.99327039718628, 97.6632297039032, 95.89743614196777)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.91756129264832, 98.60252141952515, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(89.11290168762207, 97.98396825790405, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(88.62007260322571, 97.98396825790405, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.93369436264038, 97.91523814201355, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(88.84408473968506, 97.91523814201355, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(89.06810283660889, 97.8694200515747, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(89.06810283660889, 97.8694200515747, 88.20512890815735)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.57775545120239, 98.5567033290863, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.72196102142334, 97.38832116127014, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.69839930534363, 97.54868745803833, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.69839930534363, 97.41122722625732, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.67483162879944, 97.47995734214783, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.74552273750305, 97.22794890403748, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.76908445358276, 97.29667901992798, 93.33333373069763)\n",
      "\n",
      "swin_large_patch4_window12_384_in22k\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(81.82254433631897, 99.58686828613281, 84.10256505012512)\n",
      "5 ites of self-training ...\n",
      "(84.43645238876343, 99.19669032096863, 84.61538553237915)\n",
      "5 ites of self-training ...\n",
      "(84.67625975608826, 99.1507887840271, 84.10256505012512)\n",
      "5 ites of self-training ...\n",
      "(84.98800992965698, 99.28849935531616, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(84.96403098106384, 99.24259781837463, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(84.8681092262268, 99.3573546409607, 84.10256505012512)\n",
      "5 ites of self-training ...\n",
      "(84.8681092262268, 99.28849935531616, 84.10256505012512)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.92082691192627, 99.60982203483582, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.05183696746826, 99.21964406967163, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.98115181922913, 99.33440089225769, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(95.14608979225159, 99.12784099578857, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(95.1225221157074, 99.24259781837463, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.09896039962769, 99.1507887840271, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(95.09896039962769, 99.31145310401917, 93.33333373069763)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(88.39605450630188, 99.63277578353882, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(89.69534039497375, 99.33440089225769, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(89.42652344703674, 99.47211146354675, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(89.60573673248291, 99.42620992660522, 87.17948794364929)\n",
      "5 ites of self-training ...\n",
      "(89.69534039497375, 99.40325617790222, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(89.56093192100525, 99.40325617790222, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(89.51612710952759, 99.3573546409607, 87.69230842590332)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.72897744178772, 99.81977939605713, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.97837424278259, 99.66208338737488, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.8582410812378, 99.66208338737488, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(95.07448673248291, 99.77472424507141, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(95.00240087509155, 99.7296690940857, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(94.97837424278259, 99.7071385383606, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(94.97837424278259, 99.7071385383606, 95.89743614196777)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(79.40047979354858, 99.79724884033203, 76.4102578163147)\n",
      "5 ites of self-training ...\n",
      "(82.1342945098877, 99.45933818817139, 79.48718070983887)\n",
      "5 ites of self-training ...\n",
      "(82.15827345848083, 99.39175248146057, 80.51282167434692)\n",
      "5 ites of self-training ...\n",
      "(82.25419521331787, 99.481862783432, 80.0000011920929)\n",
      "5 ites of self-training ...\n",
      "(82.35012292861938, 99.45933818817139, 80.51282167434692)\n",
      "5 ites of self-training ...\n",
      "(82.25419521331787, 99.43680763244629, 80.51282167434692)\n",
      "5 ites of self-training ...\n",
      "(82.20623731613159, 99.45933818817139, 80.51282167434692)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.24551892280579, 99.81977939605713, 85.6410264968872)\n",
      "5 ites of self-training ...\n",
      "(89.06810283660889, 99.66208338737488, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(89.06810283660889, 99.7296690940857, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(89.11290168762207, 99.66208338737488, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(89.06810283660889, 99.63955879211426, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(89.29211497306824, 99.63955879211426, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(89.42652344703674, 99.66208338737488, 89.74359035491943)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.8840696811676, 99.62916970252991, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.58058476448059, 99.54676628112793, 93.33333373069763)\n",
      "5 ites of self-training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94.50989365577698, 99.5055615901947, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.72196102142334, 99.54676628112793, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.72196102142334, 99.58796501159668, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.58058476448059, 99.62916970252991, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.58058476448059, 99.62916970252991, 93.84615421295166)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(80.26378750801086, 99.62916970252991, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(83.76498818397522, 99.58796501159668, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(84.02878046035767, 99.62916970252991, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(84.1966450214386, 99.62916970252991, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(84.14868116378784, 99.62916970252991, 84.61538553237915)\n",
      "5 ites of self-training ...\n",
      "(84.07673835754395, 99.62916970252991, 84.10256505012512)\n",
      "5 ites of self-training ...\n",
      "(84.10072326660156, 99.62916970252991, 84.10256505012512)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.29649209976196, 99.62916970252991, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.49783563613892, 99.62916970252991, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(94.449782371521, 99.58796501159668, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(94.49783563613892, 99.62916970252991, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(94.59394812583923, 99.62916970252991, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(94.59394812583923, 99.62916970252991, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.64200139045715, 99.62916970252991, 95.38461565971375)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(91.75876975059509, 98.64833950996399, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(93.89716386795044, 98.07560443878174, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.96924376487732, 98.14433455467224, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.99327039718628, 98.00687432289124, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.06535625457764, 98.00687432289124, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.0893828868866, 98.16724061965942, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.96924376487732, 98.09851050376892, 95.38461565971375)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(87.94803023338318, 98.64833950996399, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(89.60573673248291, 98.16724061965942, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(89.29211497306824, 98.07560443878174, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(89.24731016159058, 98.09851050376892, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(88.97849321365356, 98.23597073554993, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(89.06810283660889, 98.14433455467224, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(88.75448107719421, 98.12142252922058, 88.20512890815735)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.03581213951111, 98.6254334449768, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.25070881843567, 97.70905375480652, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.15645599365234, 97.70905375480652, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.13289427757263, 97.8694200515747, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.10933256149292, 97.57159352302551, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.06220316886902, 97.75487184524536, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.08576488494873, 97.7319598197937, 94.35897469520569)\n",
      "\n",
      "(augmentation, shots):  ('none', 3)\n",
      "================================================================================\n",
      "Results for each ensemble member\n",
      "================================================================================\n",
      "Net, R->C, R->P, R->A, P->R, P->C, P->A, A->P, A->C, A->R, C->R, C->A, C->P, \n",
      "convnext_xlarge_384_in22ft1k, 83.86090993881226, 95.92365622520447, 90.59139490127563, 94.449782371521, 81.9904088973999, 89.6505355834961, 95.47596573829651, 83.2374095916748, 94.28159594535828, 93.89716386795044, 89.82974886894226, 94.62770819664001, \n",
      "convnext_xlarge_in22ft1k, 84.41247344017029, 94.8868989944458, 89.9193525314331, 94.11340951919556, 82.70983099937439, 89.3369197845459, 94.83977556228638, 83.64508748054504, 93.89716386795044, 93.94521713256836, 88.62007260322571, 94.29783225059509, \n",
      "convnext_xlarge_in22k, 84.89208817481995, 95.47596573829651, 89.6505355834961, 94.69005465507507, 82.39808082580566, 88.88888955116272, 94.8868989944458, 83.33333134651184, 94.23354268074036, 93.9211905002594, 88.70967626571655, 94.72196102142334, \n",
      "swin_large_patch4_window7_224, 83.42925906181335, 94.67483162879944, 87.99282908439636, 94.25756931304932, 83.3812952041626, 88.30645084381104, 94.13289427757263, 83.54915976524353, 94.2095160484314, 94.13743615150452, 87.85842061042786, 93.68520379066467, \n",
      "swin_large_patch4_window7_224_in22k, 84.50839519500732, 95.14608979225159, 87.67921328544617, 94.3296492099762, 82.51798748970032, 87.94803023338318, 94.50989365577698, 82.54196643829346, 94.30562257766724, 93.5127317905426, 87.94803023338318, 93.28463673591614, \n",
      "swin_large_patch4_window12_384, 84.67625975608826, 95.28746604919434, 88.84408473968506, 94.54588890075684, 82.90168046951294, 89.29211497306824, 94.48633193969727, 83.93285274505615, 94.11340951919556, 93.99327039718628, 89.06810283660889, 94.76908445358276, \n",
      "swin_large_patch4_window12_384_in22k, 84.8681092262268, 95.09896039962769, 89.51612710952759, 94.97837424278259, 82.20623731613159, 89.42652344703674, 94.58058476448059, 84.10072326660156, 94.64200139045715, 93.96924376487732, 88.75448107719421, 94.08576488494873, \n",
      "\n",
      "================================================================================\n",
      "Simple Majority vote\n",
      "================================================================================\n",
      "R->C, R->P, R->A, P->R, P->C, P->A, A->P, A->C, A->R, C->R, C->A, C->P, \n",
      "85.9472393989563, 95.7351565361023, 90.18816947937012, 95.21864652633667, 84.58033800125122, 90.27777910232544, 95.40528059005737, 84.98800992965698, 94.93032097816467, 94.78616118431091, 90.32257795333862, 95.24033665657043, \n",
      "\n",
      "================================================================================\n",
      "Simple Average (Usually better)\n",
      "================================================================================\n",
      "R->C, R->P, R->A, P->R, P->C, P->A, A->P, A->C, A->R, C->R, C->A, C->P, \n",
      "86.04316711425781, 95.7351565361023, 90.45698642730713, 95.19461989402771, 84.67625975608826, 90.45698642730713, 95.4524040222168, 85.15587449073792, 95.09850740432739, 94.90629434585571, 90.32257795333862, 95.26390433311462, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "! python get_results.py --augmentation none --dataset office_home --shots 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c99ce184",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(augmentation='none', dataset='multi', shots=3)\n",
      "convnext_xlarge_384_in22ft1k\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(76.94406509399414, 94.96716856956482, 80.95237612724304)\n",
      "5 ites of self-training ...\n",
      "(80.46930432319641, 93.59418749809265, 81.21693134307861)\n",
      "5 ites of self-training ...\n",
      "(81.10777735710144, 93.36251616477966, 82.27512836456299)\n",
      "5 ites of self-training ...\n",
      "(81.7353367805481, 92.98303127288818, 82.0105791091919)\n",
      "5 ites of self-training ...\n",
      "(81.92087411880493, 92.9673969745636, 82.0105791091919)\n",
      "5 ites of self-training ...\n",
      "(81.6753089427948, 92.89917349815369, 83.33333134651184)\n",
      "5 ites of self-training ...\n",
      "(81.7189633846283, 92.80821084976196, 83.06878209114075)\n",
      "\n",
      "convnext_xlarge_in22ft1k\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(76.66575908660889, 94.69285607337952, 79.10052537918091)\n",
      "5 ites of self-training ...\n",
      "(80.27831315994263, 93.37388873100281, 82.0105791091919)\n",
      "5 ites of self-training ...\n",
      "(80.87858557701111, 93.13084483146667, 83.06878209114075)\n",
      "5 ites of self-training ...\n",
      "(81.39154314994812, 92.81815886497498, 83.06878209114075)\n",
      "5 ites of self-training ...\n",
      "(81.2824010848999, 92.79826283454895, 83.33333134651184)\n",
      "5 ites of self-training ...\n",
      "(81.24420642852783, 92.67602562904358, 83.33333134651184)\n",
      "5 ites of self-training ...\n",
      "(81.2223732471466, 92.64475703239441, 83.06878209114075)\n",
      "\n",
      "convnext_xlarge_in22k\n",
      "CORAL alignment ...\n",
      "get_results.py:68: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:240.)\n",
      "  x_s_whitened = torch.matmul(x_s_n, x_s_cov_sqrt_inv.float()) # whiten\n",
      "Train classifier on labeled ...\n",
      "(75.75989365577698, 94.82645988464355, 80.42327761650085)\n",
      "5 ites of self-training ...\n",
      "(80.40382266044617, 93.3767318725586, 82.80423283576965)\n",
      "5 ites of self-training ...\n",
      "(81.2824010848999, 93.03135275840759, 83.06878209114075)\n",
      "5 ites of self-training ...\n",
      "(82.25920796394348, 92.60212182998657, 83.59788060188293)\n",
      "5 ites of self-training ...\n",
      "(82.23192691802979, 92.49552488327026, 83.33333134651184)\n",
      "5 ites of self-training ...\n",
      "(82.10095763206482, 92.27806329727173, 82.80423283576965)\n",
      "5 ites of self-training ...\n",
      "(82.16643929481506, 92.18994379043579, 83.06878209114075)\n",
      "\n",
      "swin_large_patch4_window7_224\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(75.8090078830719, 94.54077482223511, 80.15872836112976)\n",
      "5 ites of self-training ...\n",
      "(79.89085912704468, 93.09531450271606, 84.92063283920288)\n",
      "5 ites of self-training ...\n",
      "(80.72032928466797, 92.774099111557, 84.65608358383179)\n",
      "5 ites of self-training ...\n",
      "(81.39154314994812, 92.2965407371521, 84.3915343284607)\n",
      "5 ites of self-training ...\n",
      "(81.45157098770142, 92.11461544036865, 84.3915343284607)\n",
      "5 ites of self-training ...\n",
      "(81.358802318573, 91.96253418922424, 84.12697911262512)\n",
      "5 ites of self-training ...\n",
      "(81.43519759178162, 91.89857840538025, 84.12697911262512)\n",
      "\n",
      "swin_large_patch4_window7_224_in22k\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(75.07776618003845, 94.50382590293884, 80.68782687187195)\n",
      "5 ites of self-training ...\n",
      "(80.30014038085938, 92.84232258796692, 83.86242985725403)\n",
      "5 ites of self-training ...\n",
      "(81.21691942214966, 92.38892197608948, 84.12697911262512)\n",
      "5 ites of self-training ...\n",
      "(81.93724751472473, 91.88862442970276, 84.12697911262512)\n",
      "5 ites of self-training ...\n",
      "(81.97544813156128, 91.7223334312439, 84.12697911262512)\n",
      "5 ites of self-training ...\n",
      "(82.04638957977295, 91.57309532165527, 83.86242985725403)\n",
      "5 ites of self-training ...\n",
      "(81.95361495018005, 91.5517807006836, 84.12697911262512)\n",
      "\n",
      "swin_large_patch4_window12_384\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(76.8949568271637, 94.87904906272888, 81.4814805984497)\n",
      "5 ites of self-training ...\n",
      "(80.9822678565979, 93.52880716323853, 83.86242985725403)\n",
      "5 ites of self-training ...\n",
      "(81.58799409866333, 93.17348599433899, 84.3915343284607)\n",
      "5 ites of self-training ...\n",
      "(82.33560919761658, 92.69734621047974, 84.12697911262512)\n",
      "5 ites of self-training ...\n",
      "(82.2810411453247, 92.6348090171814, 83.33333134651184)\n",
      "5 ites of self-training ...\n",
      "(82.41201043128967, 92.46283173561096, 84.12697911262512)\n",
      "5 ites of self-training ...\n",
      "(82.428377866745, 92.34344363212585, 84.12697911262512)\n",
      "\n",
      "swin_large_patch4_window12_384_in22k\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(76.1255145072937, 94.82361674308777, 80.15872836112976)\n",
      "5 ites of self-training ...\n",
      "(81.11323714256287, 93.18912029266357, 84.12697911262512)\n",
      "5 ites of self-training ...\n",
      "(82.1118712425232, 92.7541971206665, 83.86242985725403)\n",
      "5 ites of self-training ...\n",
      "(82.82673954963684, 92.25532412528992, 84.3915343284607)\n",
      "5 ites of self-training ...\n",
      "(82.90859460830688, 92.16009378433228, 84.65608358383179)\n",
      "5 ites of self-training ...\n",
      "(82.79945850372314, 91.94405674934387, 83.59788060188293)\n",
      "5 ites of self-training ...\n",
      "(82.73943066596985, 91.94974303245544, 83.06878209114075)\n",
      "\n",
      "(augmentation, shots):  ('none', 3)\n",
      "================================================================================\n",
      "Results for each ensemble member\n",
      "================================================================================\n",
      "Net, r->c, \n",
      "convnext_xlarge_384_in22ft1k, 81.7189633846283, \n",
      "convnext_xlarge_in22ft1k, 81.2223732471466, \n",
      "convnext_xlarge_in22k, 82.16643929481506, \n",
      "swin_large_patch4_window7_224, 81.43519759178162, \n",
      "swin_large_patch4_window7_224_in22k, 81.95361495018005, \n",
      "swin_large_patch4_window12_384, 82.428377866745, \n",
      "swin_large_patch4_window12_384_in22k, 82.73943066596985, \n",
      "\n",
      "================================================================================\n",
      "Simple Majority vote\n",
      "================================================================================\n",
      "r->c, \n",
      "83.95634293556213, \n",
      "\n",
      "================================================================================\n",
      "Simple Average (Usually better)\n",
      "================================================================================\n",
      "r->c, \n",
      "84.01091694831848, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "! python get_results.py --augmentation none --dataset multi --shots 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af5449b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(T=30, alpha0=0.4, alpha1T=0.1, augmentation='none', beta0=0.2, beta1T=0.05, dataset='multi', eta0=40, eta1T=80, gamma1T=0.9, save_weights=False, shots=3, taus1T=0.8, tautu110=0.9, tautu1120=0.8, tautu2130=0.7)\n",
      "convnext_xlarge_384_in22ft1k\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(76.88403725624084, 94.95153427124023, 80.95237612724304)\n",
      "5 ites of self-training ...\n",
      "(80.48567771911621, 93.59845519065857, 80.95237612724304)\n",
      "5 ites of self-training ...\n",
      "(81.01500868797302, 93.35682988166809, 81.7460298538208)\n",
      "5 ites of self-training ...\n",
      "(81.71350955963135, 93.00150871276855, 83.06878209114075)\n",
      "5 ites of self-training ...\n",
      "(81.78990483283997, 92.99866557121277, 82.0105791091919)\n",
      "5 ites of self-training ...\n",
      "(81.58254027366638, 92.84800291061401, 82.80423283576965)\n",
      "5 ites of self-training ...\n",
      "(81.54433965682983, 92.85653233528137, 82.0105791091919)\n",
      "\n",
      "convnext_xlarge_in22ft1k\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(76.67121887207031, 94.70138549804688, 79.10052537918091)\n",
      "5 ites of self-training ...\n",
      "(80.18008470535278, 93.39520931243896, 82.0105791091919)\n",
      "5 ites of self-training ...\n",
      "(80.86767196655273, 93.14363598823547, 83.06878209114075)\n",
      "5 ites of self-training ...\n",
      "(81.22783303260803, 92.76699423789978, 83.06878209114075)\n",
      "5 ites of self-training ...\n",
      "(81.26603364944458, 92.78830885887146, 83.86242985725403)\n",
      "5 ites of self-training ...\n",
      "(81.03683590888977, 92.68739819526672, 83.86242985725403)\n",
      "5 ites of self-training ...\n",
      "(81.08595013618469, 92.62770414352417, 83.86242985725403)\n",
      "\n",
      "convnext_xlarge_in22k\n",
      "CORAL alignment ...\n",
      "get_results.py:85: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:240.)\n",
      "  x_s_whitened = torch.matmul(x_s_n, x_s_cov_sqrt_inv.float()) # whiten\n",
      "Train classifier on labeled ...\n",
      "(75.73806643486023, 94.8179304599762, 80.42327761650085)\n",
      "5 ites of self-training ...\n",
      "(80.46930432319641, 93.38383674621582, 83.06878209114075)\n",
      "5 ites of self-training ...\n",
      "(81.26057386398315, 93.00718903541565, 83.06878209114075)\n",
      "5 ites of self-training ...\n",
      "(82.18826651573181, 92.58506298065186, 83.33333134651184)\n",
      "5 ites of self-training ...\n",
      "(82.21555352210999, 92.47704744338989, 83.59788060188293)\n",
      "5 ites of self-training ...\n",
      "(82.23192691802979, 92.32496619224548, 83.06878209114075)\n",
      "5 ites of self-training ...\n",
      "(82.22101330757141, 92.18994379043579, 83.06878209114075)\n",
      "\n",
      "swin_large_patch4_window7_224\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(75.78718066215515, 94.54077482223511, 80.15872836112976)\n",
      "5 ites of self-training ...\n",
      "(79.92905974388123, 93.10383796691895, 84.92063283920288)\n",
      "5 ites of self-training ...\n",
      "(80.75307011604309, 92.76272654533386, 84.92063283920288)\n",
      "5 ites of self-training ...\n",
      "(81.33151531219482, 92.24821329116821, 84.65608358383179)\n",
      "5 ites of self-training ...\n",
      "(81.3424289226532, 92.14730262756348, 84.92063283920288)\n",
      "5 ites of self-training ...\n",
      "(81.32606148719788, 92.00517535209656, 84.65608358383179)\n",
      "5 ites of self-training ...\n",
      "(81.27694725990295, 91.96679592132568, 85.18518209457397)\n",
      "\n",
      "swin_large_patch4_window7_224_in22k\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(75.0832200050354, 94.50098276138306, 80.68782687187195)\n",
      "5 ites of self-training ...\n",
      "(80.32196760177612, 92.85368919372559, 83.86242985725403)\n",
      "5 ites of self-training ...\n",
      "(81.2551200389862, 92.37897396087646, 84.12697911262512)\n",
      "5 ites of self-training ...\n",
      "(81.98090195655823, 91.91847443580627, 84.3915343284607)\n",
      "5 ites of self-training ...\n",
      "(82.01910257339478, 91.76213145256042, 84.65608358383179)\n",
      "5 ites of self-training ...\n",
      "(81.98090195655823, 91.53472185134888, 83.86242985725403)\n",
      "5 ites of self-training ...\n",
      "(81.9918155670166, 91.48355722427368, 84.12697911262512)\n",
      "\n",
      "swin_large_patch4_window12_384\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(76.94406509399414, 94.87193822860718, 81.4814805984497)\n",
      "5 ites of self-training ...\n",
      "(80.98772168159485, 93.52596402168274, 83.86242985725403)\n",
      "5 ites of self-training ...\n",
      "(81.62619471549988, 93.18627715110779, 84.12697911262512)\n",
      "5 ites of self-training ...\n",
      "(82.341068983078, 92.72150993347168, 83.86242985725403)\n",
      "5 ites of self-training ...\n",
      "(82.30286836624146, 92.65328645706177, 83.86242985725403)\n",
      "5 ites of self-training ...\n",
      "(82.3083221912384, 92.48273372650146, 84.12697911262512)\n",
      "5 ites of self-training ...\n",
      "(82.3246955871582, 92.418771982193, 84.65608358383179)\n",
      "\n",
      "swin_large_patch4_window12_384_in22k\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(76.0818600654602, 94.82361674308777, 80.15872836112976)\n",
      "5 ites of self-training ...\n",
      "(81.09140992164612, 93.20617318153381, 84.12697911262512)\n",
      "5 ites of self-training ...\n",
      "(82.13369846343994, 92.75277853012085, 83.86242985725403)\n",
      "5 ites of self-training ...\n",
      "(82.84856677055359, 92.30648875236511, 84.65608358383179)\n",
      "5 ites of self-training ...\n",
      "(82.91405439376831, 92.21552610397339, 84.65608358383179)\n",
      "5 ites of self-training ...\n",
      "(82.96862244606018, 91.93126559257507, 84.3915343284607)\n",
      "5 ites of self-training ...\n",
      "(82.94134140014648, 91.98527336120605, 84.12697911262512)\n",
      "\n",
      "(augmentation, shots):  ('none', 3)\n",
      "================================================================================\n",
      "Results for each ensemble member\n",
      "================================================================================\n",
      "Net, r->c, \n",
      "convnext_xlarge_384_in22ft1k, 81.54433965682983, \n",
      "convnext_xlarge_in22ft1k, 81.08595013618469, \n",
      "convnext_xlarge_in22k, 82.22101330757141, \n",
      "swin_large_patch4_window7_224, 81.27694725990295, \n",
      "swin_large_patch4_window7_224_in22k, 81.9918155670166, \n",
      "swin_large_patch4_window12_384, 82.3246955871582, \n",
      "swin_large_patch4_window12_384_in22k, 82.94134140014648, \n",
      "\n",
      "================================================================================\n",
      "Simple Majority vote\n",
      "================================================================================\n",
      "r->c, \n",
      "83.84720087051392, \n",
      "\n",
      "================================================================================\n",
      "Simple Average (Usually better)\n",
      "================================================================================\n",
      "r->c, \n",
      "83.93997550010681, \n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Simple Average on Target validation set\n",
      "================================================================================\n",
      "r->c, \n",
      "85.18518805503845, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "! python get_results.py --augmentation none --dataset multi --shots 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed67f4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_hyper_0.sh\n",
      "run_hyper_1.sh\n",
      "run_hyper_2.sh\n",
      "run_hyper_3.sh\n",
      "run_hyper_4.sh\n",
      "run_hyper_5.sh\n",
      "run_hyper_6.sh\n",
      "run_hyper_7.sh\n",
      "run_hyper_8.sh\n",
      "run_hyper_9.sh\n",
      "run_hyper_10.sh\n",
      "run_hyper_11.sh\n",
      "run_hyper_12.sh\n",
      "run_hyper_13.sh\n",
      "run_hyper_14.sh\n",
      "run_hyper_15.sh\n",
      "run_hyper_16.sh\n",
      "run_hyper_17.sh\n",
      "run_hyper_18.sh\n",
      "run_hyper_19.sh\n",
      "run_hyper_20.sh\n",
      "run_hyper_21.sh\n",
      "run_hyper_22.sh\n",
      "run_hyper_23.sh\n",
      "run_hyper_24.sh\n",
      "run_hyper_25.sh\n",
      "run_hyper_normal.sh\n"
     ]
    }
   ],
   "source": [
    "# generate hyperparameter file\n",
    "\n",
    "command = '''#!/bin/bash -l\n",
    "module load python3/3.8.10 pytorch/1.9.0\n",
    "python get_results_UDA.py --augmentation none --dataset office_home \\\n",
    "--T {0} --eta0 {1} --eta1T {2} --alpha0 {3} --beta0 {4} --alpha1T {5} --beta1T {6} \\\n",
    "--gamma1T {7} --taus1T {8} --tautu110 {9} --tautu1120 {10} --tautu2130 {11}\n",
    "\n",
    "python get_results_UDA.py --augmentation none --dataset office_home \\\n",
    "--T {0} --eta0 {1} --eta1T {2} --alpha0 {3} --beta0 {4} --alpha1T {5} --beta1T {6} \\\n",
    "--gamma1T {7} --taus1T {8} --tautu110 {9} --tautu1120 {10} --tautu2130 {11}\n",
    "\n",
    "python get_results_UDA.py --augmentation none --dataset office_home \\\n",
    "--T {0} --eta0 {1} --eta1T {2} --alpha0 {3} --beta0 {4} --alpha1T {5} --beta1T {6} \\\n",
    "--gamma1T {7} --taus1T {8} --tautu110 {9} --tautu1120 {10} --tautu2130 {11}\n",
    "'''\n",
    "\n",
    "T=30\n",
    "eta0=40\n",
    "eta1T=80\n",
    "alpha0=0.4\n",
    "beta0=0.2\n",
    "alpha1T=0.1\n",
    "beta1T=0.05\n",
    "gamma1T=0.9\n",
    "taus1T=0.8\n",
    "tautu110=0.9\n",
    "tautu1120=0.8\n",
    "tautu2130=0.7\n",
    "\n",
    "i = 0\n",
    "fname = 'run_hyper_{}.sh'\n",
    "\n",
    "qsubs = '''qsub -l gpus=1 -l gpu_c=6.0 -l h_rt=4:00:00 -N \"{0}\" -o \"{0}.o\" -j y -m bea -pe omp 4 {0}.sh\n",
    "'''\n",
    "\n",
    "ff = open('scc_batch.sh', 'w')\n",
    "\n",
    "# Different learning rates 0\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0/2, eta1T/2, alpha0, beta0, alpha1T, beta1T, gamma1T, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0*2, eta1T*2, alpha0, beta0, alpha1T, beta1T, gamma1T, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "# Different T 2\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(10, eta0, eta1T, alpha0, beta0, alpha1T, beta1T, gamma1T, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(20, eta0, eta1T, alpha0, beta0, alpha1T, beta1T, gamma1T, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "# Different alpha_0, beta_0 4\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, 0.5, 0.1, alpha1T, beta1T, gamma1T, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, 0.3, 0.3, alpha1T, beta1T, gamma1T, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "# Different alpha, beta, gamma 6\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, alpha0, beta0, 0.2, 0.05, 0.8, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, alpha0, beta0, 0.05, 0.05, 0.95, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "# Different tau s 8\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, alpha0, beta0, alpha1T, beta1T, gamma1T, 0.9, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, alpha0, beta0, alpha1T, beta1T, gamma1T, 0.7, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "# Different tau tu 10\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, alpha0, beta0, alpha1T, beta1T, gamma1T, taus1T, 0.95, 0.85, 0.75)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, alpha0, beta0, alpha1T, beta1T, gamma1T, taus1T, 0.8, 0.7, 0.6)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "# Different learning rates 12\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0/4, eta1T/4, alpha0, beta0, alpha1T, beta1T, gamma1T, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0*4, eta1T*4, alpha0, beta0, alpha1T, beta1T, gamma1T, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "# Different alpha_0, beta_0 14\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, 0.55, 0.05, alpha1T, beta1T, gamma1T, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, 0.2, 0.4, alpha1T, beta1T, gamma1T, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "# Different alpha, beta, gamma 16\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, alpha0, beta0, 0.4, 0.05, 0.6, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, alpha0, beta0, 0.3, 0.05, 0.7, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "# Different tau s 18\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, alpha0, beta0, alpha1T, beta1T, gamma1T, 0.95, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, alpha0, beta0, alpha1T, beta1T, gamma1T, 0.6, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "# Different tau tu 20\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, alpha0, beta0, alpha1T, beta1T, gamma1T, taus1T, 0.975, 0.95, 0.9)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, alpha0, beta0, alpha1T, beta1T, gamma1T, taus1T, 0.7, 0.6, 0.5)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "# Different alpha_0, beta_0 22\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, 0.1, 0.5, alpha1T, beta1T, gamma1T, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, 0.05, 0.55, alpha1T, beta1T, gamma1T, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "# Different alpha, beta, gamma 24\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, alpha0, beta0, 0.5, 0.05, 0.5, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "fn = fname.format(i)\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, alpha0, beta0, 0.6, 0.05, 0.4, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "fn = fname.format('normal')\n",
    "i += 1\n",
    "print(fn)\n",
    "with open(fn, 'w') as g:\n",
    "    fs = command.format(T, eta0, eta1T, alpha0, beta0, alpha1T, beta1T, gamma1T, taus1T, tautu110, tautu1120, tautu2130)\n",
    "    g.write(fs)\n",
    "ff.write(qsubs.format(fn.split('.')[0]))\n",
    "\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e4901b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_hyper_0.o, 84.14188027381897, 85.71428656578064, 84.09277200698853, 85.71428656578064, 84.20190811157227, 85.71428656578064, \n",
      "run_hyper_1.o, 83.80900621414185, 86.24338507652283, 83.79809260368347, 85.97883582115173, 83.76534581184387, 85.71428656578064, \n",
      "run_hyper_2.o, 83.38881134986877, 84.92063283920288, 83.42155814170837, 85.18518805503845, 83.41063857078552, 84.92063283920288, \n",
      "run_hyper_3.o, 84.03274416923523, 85.18518805503845, 84.0436577796936, 84.92063283920288, 84.04911160469055, 85.44973731040955, \n",
      "run_hyper_4.o, 83.87448787689209, 85.44973731040955, 83.88540148735046, 85.71428656578064, 83.87994766235352, 85.18518805503845, \n",
      "run_hyper_5.o, 83.93451571464539, 85.18518805503845, 83.98908376693726, 85.18518805503845, 84.0272843837738, 84.65608358383179, \n",
      "run_hyper_6.o, 83.8308334350586, 85.44973731040955, 83.90722870826721, 84.92063283920288, 84.0272843837738, 84.92063283920288, \n",
      "run_hyper_7.o, 84.0873122215271, 85.97883582115173, 84.0272843837738, 85.71428656578064, 84.05457139015198, 86.24338507652283, \n",
      "run_hyper_8.o, 83.96180272102356, 84.92063283920288, 84.1036856174469, 85.18518805503845, 84.03274416923523, 85.18518805503845, \n",
      "run_hyper_9.o, 84.1036856174469, 85.71428656578064, 84.00545716285706, 85.97883582115173, 84.09822583198547, 86.77248954772949, \n",
      "run_hyper_10.o, 84.11459922790527, 85.18518805503845, 84.15825366973877, 85.44973731040955, 84.06002521514893, 85.18518805503845, \n",
      "run_hyper_11.o, 83.26330184936523, 85.44973731040955, 83.27421545982361, 85.97883582115173, 83.19781422615051, 85.44973731040955, \n",
      "run_hyper_12.o, 83.88540148735046, 85.44973731040955, 83.90177488327026, 85.71428656578064, 83.90722870826721, 85.71428656578064, \n",
      "run_hyper_13.o, 83.28512907028198, 86.77248954772949, 83.24692845344543, 86.77248954772949, 83.39972496032715, 86.24338507652283, \n",
      "run_hyper_14.o, 83.76534581184387, 85.18518805503845, 83.67257714271545, 85.18518805503845, 83.84720087051392, 85.44973731040955, \n",
      "run_hyper_15.o, 84.18008089065552, 85.44973731040955, 84.15825366973877, 84.92063283920288, 84.25102233886719, 85.18518805503845, \n",
      "run_hyper_16.o, 83.49249362945557, 85.44973731040955, 83.48158001899719, 85.44973731040955, 83.56889486312866, 85.71428656578064, \n",
      "run_hyper_17.o, 83.80900621414185, 85.18518805503845, 83.63983631134033, 84.92063283920288, 83.69986414909363, 85.44973731040955, \n",
      "run_hyper_18.o, 83.92905592918396, 85.18518805503845, 84.04911160469055, 84.92063283920288, 83.86903405189514, 85.18518805503845, \n",
      "run_hyper_19.o, 83.98908376693726, 85.71428656578064, 83.84174704551697, 85.71428656578064, 83.93451571464539, 85.97883582115173, \n",
      "run_hyper_20.o, 83.91814231872559, 85.44973731040955, 83.89086127281189, 85.18518805503845, 83.92360210418701, 85.97883582115173, \n",
      "run_hyper_21.o, 82.43383169174194, 85.44973731040955, 82.43929147720337, 85.44973731040955, 82.50477313995361, 84.92063283920288, \n",
      "run_hyper_22.o, 84.21282172203064, 85.18518805503845, 84.12005305290222, 85.18518805503845, 84.1637134552002, 85.71428656578064, \n",
      "run_hyper_23.o, 84.1309666633606, 85.44973731040955, 84.21828150749207, 85.18518805503845, 84.22919511795044, 85.18518805503845, \n",
      "run_hyper_24.o, 83.1050455570221, 85.97883582115173, 83.0777645111084, 85.71428656578064, 82.95224905014038, 85.71428656578064, \n",
      "run_hyper_25.o, 82.7012300491333, 84.92063283920288, 82.67394304275513, 85.18518805503845, 82.77762532234192, 84.92063283920288, \n"
     ]
    }
   ],
   "source": [
    "for i in range(26):\n",
    "    fn = 'run_hyper_{}.o'.format(i)\n",
    "    with open(fn) as f:\n",
    "        ll = f.readlines()\n",
    "        print(fn, end=', ')\n",
    "        for j in range(len(ll)):\n",
    "            line = ll[j]\n",
    "            if 'Simple Average (Usually better)' in line:\n",
    "                test_acc = ll[j+3].strip().split(',')[0].strip()\n",
    "                print(test_acc, end=', ')\n",
    "            elif 'Simple Average on Target validation set' in line:\n",
    "                val_acc = ll[j+3].strip().split(',')[0].strip()\n",
    "                print(val_acc, end=', ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b65f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multirun \n",
    "\n",
    "# load all the stuff in the domain\n",
    "\n",
    "# withdraw three of each category to be labeled\n",
    "\n",
    "# the rest are unlabeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d8d921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def make_dataset_fromlist(image_list):\n",
    "    # print(\"image_list\", image_list)\n",
    "    with open(image_list) as f:\n",
    "        image_index = [x.split(' ')[0] for x in f.readlines()]\n",
    "    with open(image_list) as f:\n",
    "        label_list = []\n",
    "        selected_list = []\n",
    "        for ind, x in enumerate(f.readlines()):\n",
    "            label = x.split(' ')[1].strip()\n",
    "            label_list.append(int(label))\n",
    "            selected_list.append(ind)\n",
    "        image_index = np.array(image_index)\n",
    "        label_list = np.array(label_list)\n",
    "    image_index = image_index[selected_list]\n",
    "    return image_index, label_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3306f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['Alarm_Clock', 'Backpack', 'Batteries', 'Bed', 'Bike', 'Bottle', 'Bucket', 'Calculator', 'Calendar', 'Candles', 'Chair', 'Clipboards', 'Computer', 'Couch', 'Curtains', 'Desk_Lamp', 'Drill', 'Eraser', 'Exit_Sign', 'Fan', 'File_Cabinet', 'Flipflops', 'Flowers', 'Folder', 'Fork', 'Glasses', 'Hammer', 'Helmet', 'Kettle', 'Keyboard', 'Knives', 'Lamp_Shade', 'Laptop', 'Marker', 'Monitor', 'Mop', 'Mouse', 'Mug', 'Notebook', 'Oven', 'Pan', 'Paper_Clip', 'Pen', 'Pencil', 'Postit_Notes', 'Printer', 'Push_Pin', 'Radio', 'Refrigerator', 'Ruler', 'Scissors', 'Screwdriver', 'Shelf', 'Sink', 'Sneakers', 'Soda', 'Speaker', 'Spoon', 'Table', 'Telephone', 'ToothBrush', 'Toys', 'Trash_Can', 'TV', 'Webcam']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "264bb2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Clipart'\n",
    "root = 'data/office_home/'\n",
    "image_list_file_path = root + 'unique_image_paths_{}.txt'.format(target)\n",
    "image_paths, labels = make_dataset_fromlist(image_list_file_path)\n",
    "\n",
    "dd = {}\n",
    "for image in image_paths:\n",
    "    label = image.split('/')[1]\n",
    "    assert label in class_list\n",
    "    ind = class_list.index(label)\n",
    "    if not ind in dd:\n",
    "        dd[ind] = [image]\n",
    "    else:\n",
    "        dd[ind].append(image)\n",
    "        \n",
    "labeled_images_filename = root + 'labeled_target_images_{}_3.txt'.format(target)\n",
    "unlabeled_images_filename = root + 'unlabeled_target_images_{}_3.txt'.format(target)\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "labeled_images_file = open(labeled_images_filename, 'w')\n",
    "unlabeled_images_file = open(unlabeled_images_filename, 'w')\n",
    "\n",
    "for ind in range(len(class_list)):\n",
    "    shuffle(dd[ind])\n",
    "    # three labeled\n",
    "    labeled_images = dd[ind][:3]\n",
    "    unlabeled_images = dd[ind][3:]\n",
    "    for image in labeled_images:\n",
    "        labeled_images_file.write(image + ' ' + str(ind) + '\\n')\n",
    "    for image in unlabeled_images:\n",
    "        unlabeled_images_file.write(image + ' ' + str(ind) + '\\n')\n",
    "    \n",
    "labeled_images_file.close()\n",
    "unlabeled_images_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ce63d9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(T=30, alpha0=0.4, alpha1T=0.1, augmentation='none', beta0=0.2, beta1T=0.05, dataset='office_home', eta0=40, eta1T=80, gamma1T=0.9, save_weights=False, shots=3, taus1T=0.8, tautu110=0.9, tautu1120=0.8, tautu2130=0.7)\n",
      "convnext_xlarge_384_in22ft1k\n",
      "CORAL alignment ...\n",
      "get_results.py:87: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:240.)\n",
      "  x_s = torch.matmul(x_s_whitened, x_t_cov_sqrt.float()) # recolor with target variance\n",
      "Train classifier on labeled ...\n",
      "(80.45563697814941, 99.54096674919128, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(83.54915976524353, 98.78356456756592, 85.12820601463318)\n",
      "5 ites of self-training ...\n",
      "(83.74100923538208, 98.76061081886292, 85.12820601463318)\n",
      "5 ites of self-training ...\n",
      "(83.57314467430115, 98.85241985321045, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(83.50120186805725, 98.85241985321045, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(83.40527415275574, 98.92127513885498, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(83.4532380104065, 98.9442229270935, 82.56410360336304)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(94.53345537185669, 99.51801300048828, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(95.71159482002258, 98.5540509223938, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(95.64090371131897, 98.85241985321045, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(95.61734199523926, 98.76061081886292, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(95.66446542739868, 98.9442229270935, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(95.49952745437622, 98.80651831626892, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(95.52308917045593, 98.99013042449951, 95.38461565971375)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(88.03763389587402, 99.60982203483582, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(90.7706081867218, 99.10488724708557, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(90.7706081867218, 98.92127513885498, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(91.03942513465881, 99.21964406967163, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(90.90501666069031, 98.99013042449951, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(90.32257795333862, 99.12784099578857, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(90.36738276481628, 99.12784099578857, 89.74359035491943)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.91206002235413, 99.77472424507141, 91.28205180168152)\n",
      "5 ites of self-training ...\n",
      "(94.23354268074036, 99.43680763244629, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.2095160484314, 99.41428303718567, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(93.87313723564148, 99.43680763244629, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(93.99327039718628, 99.36922788619995, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.06535625457764, 99.39175248146057, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.04132962226868, 99.481862783432, 92.8205132484436)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(79.1846513748169, 99.68461394309998, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(81.41486644744873, 99.2115318775177, 84.10256505012512)\n",
      "5 ites of self-training ...\n",
      "(81.84652328491211, 99.32417273521423, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(81.75060153007507, 99.25658702850342, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(81.77458047866821, 99.25658702850342, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(81.77458047866821, 99.25658702850342, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(81.82254433631897, 99.30164217948914, 82.56410360336304)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.6487443447113, 99.77472424507141, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(89.02329802513123, 99.41428303718567, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(88.93369436264038, 99.30164217948914, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(89.11290168762207, 99.481862783432, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(88.88888955116272, 99.39175248146057, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(89.24731016159058, 99.43680763244629, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(88.93369436264038, 99.41428303718567, 90.76923131942749)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.61451268196106, 99.62916970252991, 91.28205180168152)\n",
      "5 ites of self-training ...\n",
      "(95.33458948135376, 99.34074878692627, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(95.47596573829651, 99.42315220832825, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(95.54665088653564, 99.29954409599304, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(95.54665088653564, 99.29954409599304, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(95.52308917045593, 99.3819534778595, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(95.57021856307983, 99.46435689926147, 93.33333373069763)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(79.73620891571045, 99.62916970252991, 84.10256505012512)\n",
      "5 ites of self-training ...\n",
      "(81.53477311134338, 99.3819534778595, 85.12820601463318)\n",
      "5 ites of self-training ...\n",
      "(81.46283030509949, 99.46435689926147, 85.12820601463318)\n",
      "5 ites of self-training ...\n",
      "(82.08633065223694, 99.3819534778595, 85.12820601463318)\n",
      "5 ites of self-training ...\n",
      "(82.11031556129456, 99.42315220832825, 85.12820601463318)\n",
      "5 ites of self-training ...\n",
      "(82.32613801956177, 99.42315220832825, 85.12820601463318)\n",
      "5 ites of self-training ...\n",
      "(82.30215907096863, 99.62916970252991, 85.12820601463318)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.57568717002869, 99.62916970252991, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(93.89716386795044, 99.46435689926147, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.82508397102356, 99.54676628112793, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.06535625457764, 99.54676628112793, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.06535625457764, 99.42315220832825, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.2095160484314, 99.5055615901947, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.18548941612244, 99.5055615901947, 95.38461565971375)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(91.92695617675781, 98.4879732131958, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(93.58481764793396, 97.41122722625732, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(93.48870515823364, 97.45704531669617, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(93.8010573387146, 97.2737729549408, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(93.75300407409668, 97.38832116127014, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(93.6809241771698, 97.61741161346436, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(93.65689754486084, 97.38832116127014, 94.35897469520569)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(87.76881694793701, 98.5567033290863, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(89.87455368041992, 97.57159352302551, 91.28205180168152)\n",
      "5 ites of self-training ...\n",
      "(89.82974886894226, 97.47995734214783, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(89.82974886894226, 97.59450554847717, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(89.29211497306824, 97.45704531669617, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(89.24731016159058, 97.59450554847717, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(89.24731016159058, 97.45704531669617, 90.25641083717346)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.19038391113281, 98.37342500686646, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(95.21677494049072, 96.5177595615387, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.1225221157074, 96.47193551063538, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(95.14608979225159, 96.12829685211182, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(95.1225221157074, 96.49484753608704, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(95.05183696746826, 96.42611742019653, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(95.02827525138855, 96.54066562652588, 93.33333373069763)\n",
      "\n",
      "convnext_xlarge_in22ft1k\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(81.46283030509949, 99.56392049789429, 84.61538553237915)\n",
      "5 ites of self-training ...\n",
      "(84.24460291862488, 98.76061081886292, 86.66666746139526)\n",
      "5 ites of self-training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84.10072326660156, 99.01307821273804, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(84.1966450214386, 98.87537360191345, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(84.1247022151947, 98.76061081886292, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(84.2685878276825, 98.92127513885498, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(84.34053063392639, 98.9442229270935, 86.15384697914124)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(94.18001770973206, 99.56392049789429, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(95.35815119743347, 98.78356456756592, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.4052746295929, 98.87537360191345, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.33458948135376, 98.82946610450745, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.4052746295929, 98.69175553321838, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.42884230613708, 98.99013042449951, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.38171291351318, 98.78356456756592, 93.33333373069763)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(87.27598786354065, 99.65572357177734, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(89.24731016159058, 99.19669032096863, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(89.74014520645142, 99.05898571014404, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(89.87455368041992, 99.03603196144104, 91.28205180168152)\n",
      "5 ites of self-training ...\n",
      "(89.3369197845459, 99.08193349838257, 91.28205180168152)\n",
      "5 ites of self-training ...\n",
      "(89.11290168762207, 99.19669032096863, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(89.4713282585144, 99.24259781837463, 91.28205180168152)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.88803339004517, 99.75219368934631, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(93.70495080947876, 99.34669733047485, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(93.72897744178772, 99.34669733047485, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(93.58481764793396, 99.45933818817139, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(93.58481764793396, 99.36922788619995, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(93.46467852592468, 99.45933818817139, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(93.53676438331604, 99.5043933391571, 92.30769276618958)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(79.80815172195435, 99.7071385383606, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(82.03837275505066, 99.39175248146057, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(82.27818012237549, 99.16647672653198, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(82.99760222434998, 99.2340624332428, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(83.02158117294312, 99.27911758422852, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(82.733815908432, 99.2340624332428, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(82.733815908432, 99.30164217948914, 82.05128312110901)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(85.5286717414856, 99.79724884033203, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(88.26164603233337, 99.52691793441772, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(88.3512556552887, 99.43680763244629, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(87.94803023338318, 99.481862783432, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(87.90322542190552, 99.5043933391571, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(88.39605450630188, 99.481862783432, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(88.21684718132019, 99.52691793441772, 90.25641083717346)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.67200827598572, 99.62916970252991, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.36851739883423, 99.46435689926147, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.76908445358276, 99.5055615901947, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.69839930534363, 99.54676628112793, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.67483162879944, 99.62916970252991, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.74552273750305, 99.58796501159668, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.74552273750305, 99.62916970252991, 93.84615421295166)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(80.5995225906372, 99.62916970252991, 84.10256505012512)\n",
      "5 ites of self-training ...\n",
      "(82.75779485702515, 99.42315220832825, 85.12820601463318)\n",
      "5 ites of self-training ...\n",
      "(82.78177380561829, 99.54676628112793, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(83.04556608200073, 99.5055615901947, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(82.97362327575684, 99.46435689926147, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(83.06954503059387, 99.54676628112793, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(82.92565941810608, 99.5055615901947, 86.66666746139526)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.26333498954773, 99.62916970252991, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(93.9211905002594, 99.5055615901947, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.06535625457764, 99.58796501159668, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.04132962226868, 99.58796501159668, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.06535625457764, 99.54676628112793, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.99327039718628, 99.62916970252991, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.04132962226868, 99.58796501159668, 95.89743614196777)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.09514856338501, 98.46506714820862, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(93.82508397102356, 97.25086092948914, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(93.82508397102356, 97.11340665817261, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(93.94521713256836, 97.29667901992798, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(93.84911060333252, 97.09049463272095, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(93.89716386795044, 97.29667901992798, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(93.96924376487732, 97.43413925170898, 95.89743614196777)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(85.88709831237793, 98.6254334449768, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(88.3512556552887, 97.52577543258667, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(88.08243870735168, 97.57159352302551, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(88.57526779174805, 97.54868745803833, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(88.53046298027039, 97.61741161346436, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(88.30645084381104, 97.61741161346436, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(88.17204236984253, 97.50286340713501, 89.74359035491943)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.6013171672821, 98.46506714820862, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.27427053451538, 96.70103192329407, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.3213939666748, 96.86139822006226, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.58058476448059, 96.70103192329407, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.67483162879944, 96.74685001373291, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.65126991271973, 96.70103192329407, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.6041464805603, 96.9072163105011, 93.84615421295166)\n",
      "\n",
      "convnext_xlarge_in22k\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(81.3189446926117, 99.63277578353882, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(83.3812952041626, 99.26554560661316, 85.6410264968872)\n",
      "5 ites of self-training ...\n",
      "(83.26139450073242, 99.26554560661316, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(83.3093523979187, 99.21964406967163, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(83.18945169448853, 99.24259781837463, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(83.3093523979187, 99.31145310401917, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(83.35731625556946, 99.33440089225769, 86.66666746139526)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(94.15645599365234, 99.58686828613281, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(95.02827525138855, 99.19669032096863, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(95.24033665657043, 99.28849935531616, 93.33333373069763)\n",
      "5 ites of self-training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95.33458948135376, 99.19669032096863, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(95.4052746295929, 99.26554560661316, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(95.38171291351318, 99.1507887840271, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(95.38171291351318, 99.19669032096863, 93.33333373069763)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.6487443447113, 99.65572357177734, 87.17948794364929)\n",
      "5 ites of self-training ...\n",
      "(88.57526779174805, 99.47211146354675, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.88888955116272, 99.42620992660522, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(89.20251131057739, 99.44915771484375, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(89.3369197845459, 99.42620992660522, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(89.11290168762207, 99.42620992660522, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(88.93369436264038, 99.49506521224976, 89.2307698726654)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.88803339004517, 99.79724884033203, 91.28205180168152)\n",
      "5 ites of self-training ...\n",
      "(93.87313723564148, 99.59450364112854, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(93.8010573387146, 99.66208338737488, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(93.8010573387146, 99.57197308540344, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(93.9211905002594, 99.63955879211426, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(93.84911060333252, 99.68461394309998, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(93.8010573387146, 99.68461394309998, 92.8205132484436)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(78.89688611030579, 99.77472424507141, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(82.25419521331787, 99.43680763244629, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(82.51798748970032, 99.45933818817139, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(82.75779485702515, 99.45933818817139, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(82.6378881931305, 99.52691793441772, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(82.58993029594421, 99.5043933391571, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(82.58993029594421, 99.54944849014282, 82.05128312110901)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(85.17025113105774, 99.81977939605713, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(87.5, 99.59450364112854, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(87.76881694793701, 99.77472424507141, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.44085931777954, 99.66208338737488, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(88.26164603233337, 99.66208338737488, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(87.85842061042786, 99.7071385383606, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(87.85842061042786, 99.66208338737488, 88.20512890815735)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.78982281684875, 99.62916970252991, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.08576488494873, 99.62916970252991, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.0386414527893, 99.62916970252991, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.08576488494873, 99.62916970252991, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.08576488494873, 99.62916970252991, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.08576488494873, 99.62916970252991, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.13289427757263, 99.62916970252991, 91.79487228393555)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(80.21582961082458, 99.62916970252991, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(82.68585205078125, 99.62916970252991, 85.12820601463318)\n",
      "5 ites of self-training ...\n",
      "(82.6378881931305, 99.62916970252991, 85.6410264968872)\n",
      "5 ites of self-training ...\n",
      "(82.99760222434998, 99.62916970252991, 85.12820601463318)\n",
      "5 ites of self-training ...\n",
      "(83.26139450073242, 99.62916970252991, 85.12820601463318)\n",
      "5 ites of self-training ...\n",
      "(83.42925906181335, 99.62916970252991, 85.6410264968872)\n",
      "5 ites of self-training ...\n",
      "(83.33333134651184, 99.62916970252991, 85.12820601463318)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.57568717002869, 99.62916970252991, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(93.84911060333252, 99.58796501159668, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(94.13743615150452, 99.58796501159668, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(94.35367584228516, 99.58796501159668, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(94.28159594535828, 99.58796501159668, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(94.23354268074036, 99.62916970252991, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(94.16146278381348, 99.62916970252991, 96.4102566242218)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(91.75876975059509, 98.67125153541565, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(93.6809241771698, 98.09851050376892, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(93.72897744178772, 97.98396825790405, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(93.77703070640564, 97.98396825790405, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.72897744178772, 98.07560443878174, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.63287091255188, 98.00687432289124, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(93.560791015625, 97.96105623245239, 95.38461565971375)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.20071411132812, 98.64833950996399, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.26164603233337, 98.12142252922058, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(88.17204236984253, 97.96105623245239, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(88.03763389587402, 97.93814420700073, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(88.03763389587402, 97.91523814201355, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(88.39605450630188, 98.0297863483429, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(88.53046298027039, 97.93814420700073, 89.74359035491943)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.41281747817993, 98.64833950996399, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.46277022361755, 97.70905375480652, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.58058476448059, 97.59450554847717, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.67483162879944, 97.36540913581848, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.53345537185669, 97.31959104537964, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.39207911491394, 97.36540913581848, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.36851739883423, 97.31959104537964, 94.35897469520569)\n",
      "\n",
      "swin_large_patch4_window7_224\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(81.10311627388, 99.56392049789429, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(83.02158117294312, 99.1507887840271, 87.17948794364929)\n",
      "5 ites of self-training ...\n",
      "(82.92565941810608, 99.12784099578857, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(82.90168046951294, 99.05898571014404, 85.6410264968872)\n",
      "5 ites of self-training ...\n",
      "(82.78177380561829, 99.19669032096863, 85.12820601463318)\n",
      "5 ites of self-training ...\n",
      "(82.78177380561829, 99.10488724708557, 85.12820601463318)\n",
      "5 ites of self-training ...\n",
      "(82.68585205078125, 99.1507887840271, 85.12820601463318)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.23751330375671, 99.58686828613281, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.62770819664001, 98.96717667579651, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.72196102142334, 98.92127513885498, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.65126991271973, 98.85241985321045, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.69839930534363, 98.9442229270935, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.69839930534363, 98.96717667579651, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.72196102142334, 99.01307821273804, 93.84615421295166)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.20071411132812, 99.60982203483582, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(87.94803023338318, 99.24259781837463, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(87.81362175941467, 99.31145310401917, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.44085931777954, 99.24259781837463, 88.71794939041138)\n",
      "5 ites of self-training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88.4856641292572, 99.33440089225769, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.08243870735168, 99.21964406967163, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(88.30645084381104, 99.28849935531616, 88.20512890815735)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.67179369926453, 99.75219368934631, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.01729702949524, 99.52691793441772, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.0893828868866, 99.5043933391571, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.75300407409668, 99.59450364112854, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(93.89716386795044, 99.481862783432, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(93.89716386795044, 99.61702823638916, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(93.9211905002594, 99.59450364112854, 94.35897469520569)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(79.32853698730469, 99.68461394309998, 79.48718070983887)\n",
      "5 ites of self-training ...\n",
      "(81.82254433631897, 99.2340624332428, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(82.08633065223694, 99.25658702850342, 81.02564215660095)\n",
      "5 ites of self-training ...\n",
      "(82.11031556129456, 99.27911758422852, 81.02564215660095)\n",
      "5 ites of self-training ...\n",
      "(82.0623517036438, 99.27911758422852, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(82.32613801956177, 99.41428303718567, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(82.32613801956177, 99.39175248146057, 81.53846263885498)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(84.67742204666138, 99.77472424507141, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(88.03763389587402, 99.59450364112854, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(87.67921328544617, 99.63955879211426, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(87.76881694793701, 99.57197308540344, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(87.90322542190552, 99.5043933391571, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(87.76881694793701, 99.481862783432, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(87.6344084739685, 99.5043933391571, 88.71794939041138)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(91.89443588256836, 99.62916970252991, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(93.77945065498352, 99.5055615901947, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(93.75588893890381, 99.58796501159668, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(93.85014176368713, 99.46435689926147, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(93.80301237106323, 99.46435689926147, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(93.7323272228241, 99.54676628112793, 91.28205180168152)\n",
      "5 ites of self-training ...\n",
      "(93.68520379066467, 99.58796501159668, 91.28205180168152)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(80.04796504974365, 99.62916970252991, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(82.15827345848083, 99.5055615901947, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(82.08633065223694, 99.5055615901947, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(82.58993029594421, 99.54676628112793, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(82.61390924453735, 99.5055615901947, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(82.75779485702515, 99.58796501159668, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(82.78177380561829, 99.54676628112793, 82.05128312110901)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.52763390541077, 99.62916970252991, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(93.53676438331604, 99.54676628112793, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(93.58481764793396, 99.5055615901947, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(93.58481764793396, 99.62916970252991, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(93.560791015625, 99.62916970252991, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(93.63287091255188, 99.58796501159668, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(93.560791015625, 99.54676628112793, 94.87179517745972)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(91.80682301521301, 98.64833950996399, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(93.58481764793396, 97.59450554847717, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.560791015625, 97.41122722625732, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.75300407409668, 97.64032363891602, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.75300407409668, 97.57159352302551, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(93.6809241771698, 97.41122722625732, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(93.63287091255188, 97.34249711036682, 95.89743614196777)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.20071411132812, 98.64833950996399, 87.17948794364929)\n",
      "5 ites of self-training ...\n",
      "(88.12723755836487, 97.84650802612305, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.03763389587402, 97.82360196113586, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.44085931777954, 97.75487184524536, 87.17948794364929)\n",
      "5 ites of self-training ...\n",
      "(88.53046298027039, 97.64032363891602, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(88.57526779174805, 97.57159352302551, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(88.26164603233337, 97.70905375480652, 88.20512890815735)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.0122504234314, 98.5567033290863, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(93.85014176368713, 97.18213081359863, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(93.89726519584656, 97.0446765422821, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(93.80301237106323, 97.06758260726929, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(93.80301237106323, 97.09049463272095, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(93.54382753372192, 97.06758260726929, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(93.40245127677917, 97.38832116127014, 93.33333373069763)\n",
      "\n",
      "swin_large_patch4_window7_224_in22k\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(80.6714653968811, 99.56392049789429, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(82.90168046951294, 99.21964406967163, 85.12820601463318)\n",
      "5 ites of self-training ...\n",
      "(82.99760222434998, 99.21964406967163, 84.61538553237915)\n",
      "5 ites of self-training ...\n",
      "(83.62110257148743, 99.28849935531616, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(83.71702432632446, 99.1507887840271, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(83.40527415275574, 99.28849935531616, 85.6410264968872)\n",
      "5 ites of self-training ...\n",
      "(83.42925906181335, 99.24259781837463, 85.6410264968872)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.42601299285889, 99.60982203483582, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.93402242660522, 99.1737425327301, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.98115181922913, 99.21964406967163, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.1696515083313, 99.31145310401917, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.19321322441101, 99.31145310401917, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.21677494049072, 99.26554560661316, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.21677494049072, 99.24259781837463, 93.84615421295166)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.37992739677429, 99.65572357177734, 84.61538553237915)\n",
      "5 ites of self-training ...\n",
      "(88.39605450630188, 99.42620992660522, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(88.53046298027039, 99.3573546409607, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(88.3512556552887, 99.40325617790222, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(88.21684718132019, 99.44915771484375, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(88.3512556552887, 99.42620992660522, 87.17948794364929)\n",
      "5 ites of self-training ...\n",
      "(88.12723755836487, 99.42620992660522, 86.15384697914124)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.83998012542725, 99.79724884033203, 91.28205180168152)\n",
      "5 ites of self-training ...\n",
      "(94.0893828868866, 99.7071385383606, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.06535625457764, 99.57197308540344, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.28159594535828, 99.63955879211426, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.2095160484314, 99.66208338737488, 94.35897469520569)\n",
      "5 ites of self-training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94.11340951919556, 99.66208338737488, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.16146278381348, 99.61702823638916, 94.35897469520569)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(78.34532260894775, 99.75219368934631, 81.02564215660095)\n",
      "5 ites of self-training ...\n",
      "(81.1750590801239, 99.45933818817139, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(80.93525171279907, 99.481862783432, 81.02564215660095)\n",
      "5 ites of self-training ...\n",
      "(81.46283030509949, 99.5043933391571, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(81.53477311134338, 99.45933818817139, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(81.27098679542542, 99.54944849014282, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(81.36690855026245, 99.54944849014282, 81.02564215660095)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(85.97670197486877, 99.77472424507141, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(87.54480481147766, 99.7071385383606, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(88.03763389587402, 99.61702823638916, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(87.58960366249084, 99.7296690940857, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(87.72401213645935, 99.59450364112854, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(87.90322542190552, 99.63955879211426, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(87.81362175941467, 99.66208338737488, 88.71794939041138)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.55419373512268, 99.62916970252991, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.25070881843567, 99.62916970252991, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.13289427757263, 99.62916970252991, 91.28205180168152)\n",
      "5 ites of self-training ...\n",
      "(94.27427053451538, 99.62916970252991, 91.28205180168152)\n",
      "5 ites of self-training ...\n",
      "(94.27427053451538, 99.62916970252991, 91.28205180168152)\n",
      "5 ites of self-training ...\n",
      "(94.27427053451538, 99.62916970252991, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.36851739883423, 99.62916970252991, 91.79487228393555)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(79.40047979354858, 99.62916970252991, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(82.49400854110718, 99.62916970252991, 85.6410264968872)\n",
      "5 ites of self-training ...\n",
      "(82.75779485702515, 99.58796501159668, 84.10256505012512)\n",
      "5 ites of self-training ...\n",
      "(82.92565941810608, 99.62916970252991, 84.61538553237915)\n",
      "5 ites of self-training ...\n",
      "(82.8057587146759, 99.58796501159668, 84.61538553237915)\n",
      "5 ites of self-training ...\n",
      "(82.49400854110718, 99.58796501159668, 84.61538553237915)\n",
      "5 ites of self-training ...\n",
      "(82.733815908432, 99.62916970252991, 84.61538553237915)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.38346815109253, 99.62916970252991, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(93.70495080947876, 99.58796501159668, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.63287091255188, 99.62916970252991, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(93.58481764793396, 99.58796501159668, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(93.60884428024292, 99.58796501159668, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(93.5127317905426, 99.58796501159668, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(93.5127317905426, 99.58796501159668, 94.87179517745972)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(90.86977243423462, 98.60252141952515, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(93.10427904129028, 98.12142252922058, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(92.81595349311829, 98.12142252922058, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(93.00817251205444, 98.16724061965942, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(92.96011328697205, 98.09851050376892, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(93.08025240898132, 98.14433455467224, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(93.0321991443634, 98.12142252922058, 94.35897469520569)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.11111044883728, 98.67125153541565, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(87.90322542190552, 98.16724061965942, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(87.67921328544617, 98.00687432289124, 87.17948794364929)\n",
      "5 ites of self-training ...\n",
      "(87.99282908439636, 98.0297863483429, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.21684718132019, 98.07560443878174, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(87.99282908439636, 98.12142252922058, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.12723755836487, 98.00687432289124, 88.71794939041138)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(91.96512699127197, 98.6254334449768, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(93.40245127677917, 97.8006899356842, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(93.4495747089386, 97.7319598197937, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(93.52026581764221, 97.54868745803833, 91.28205180168152)\n",
      "5 ites of self-training ...\n",
      "(93.49669814109802, 97.45704531669617, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(93.63807439804077, 97.6632297039032, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(93.66164207458496, 97.50286340713501, 92.30769276618958)\n",
      "\n",
      "swin_large_patch4_window12_384\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(81.94244503974915, 99.54096674919128, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(83.95683765411377, 99.1737425327301, 87.17948794364929)\n",
      "5 ites of self-training ...\n",
      "(83.62110257148743, 99.26554560661316, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(83.81295204162598, 99.1737425327301, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(83.57314467430115, 99.21964406967163, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(84.1247022151947, 99.26554560661316, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(83.95683765411377, 99.24259781837463, 86.15384697914124)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.70876550674438, 99.58686828613281, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.86333727836609, 99.05898571014404, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.69839930534363, 99.03603196144104, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.48633193969727, 99.08193349838257, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.46277022361755, 99.08193349838257, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.53345537185669, 99.28849935531616, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.55702304840088, 98.99013042449951, 92.8205132484436)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(87.14157938957214, 99.60982203483582, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(89.11290168762207, 99.1737425327301, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(88.93369436264038, 99.28849935531616, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(88.75448107719421, 99.21964406967163, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.88888955116272, 99.33440089225769, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(89.29211497306824, 99.3803083896637, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(89.24731016159058, 99.42620992660522, 88.71794939041138)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.22441220283508, 99.77472424507141, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(93.99327039718628, 99.52691793441772, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.11340951919556, 99.54944849014282, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.16146278381348, 99.54944849014282, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.0893828868866, 99.54944849014282, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.23354268074036, 99.61702823638916, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.23354268074036, 99.57197308540344, 93.33333373069763)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(79.83213663101196, 99.79724884033203, 78.97436022758484)\n",
      "5 ites of self-training ...\n",
      "(82.30215907096863, 99.481862783432, 84.10256505012512)\n",
      "5 ites of self-training ...\n",
      "(82.82973766326904, 99.45933818817139, 84.10256505012512)\n",
      "5 ites of self-training ...\n",
      "(82.51798748970032, 99.32417273521423, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(82.39808082580566, 99.34669733047485, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(82.23021626472473, 99.36922788619995, 84.10256505012512)\n",
      "5 ites of self-training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82.18225240707397, 99.43680763244629, 84.10256505012512)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.02150678634644, 99.81977939605713, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(88.79928588867188, 99.66208338737488, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(88.75448107719421, 99.57197308540344, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(89.15770649909973, 99.59450364112854, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(88.97849321365356, 99.66208338737488, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(89.02329802513123, 99.68461394309998, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(89.11290168762207, 99.68461394309998, 90.25641083717346)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.23751330375671, 99.62916970252991, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(94.55702304840088, 99.58796501159668, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.62770819664001, 99.5055615901947, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.95758414268494, 99.5055615901947, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.91046071052551, 99.54676628112793, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.86333727836609, 99.54676628112793, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.93402242660522, 99.54676628112793, 91.79487228393555)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(80.64748048782349, 99.62916970252991, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(83.14148783683777, 99.62916970252991, 84.61538553237915)\n",
      "5 ites of self-training ...\n",
      "(83.2374095916748, 99.54676628112793, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(83.4532380104065, 99.54676628112793, 84.10256505012512)\n",
      "5 ites of self-training ...\n",
      "(83.42925906181335, 99.62916970252991, 83.5897445678711)\n",
      "5 ites of self-training ...\n",
      "(83.42925906181335, 99.54676628112793, 83.07692408561707)\n",
      "5 ites of self-training ...\n",
      "(83.42925906181335, 99.54676628112793, 83.07692408561707)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.71984696388245, 99.62916970252991, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(93.60884428024292, 99.62916970252991, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(93.5127317905426, 99.54676628112793, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(93.63287091255188, 99.54676628112793, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(93.48870515823364, 99.58796501159668, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(93.3925986289978, 99.58796501159668, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(93.3925986289978, 99.58796501159668, 94.35897469520569)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.35944151878357, 98.57961535453796, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(93.6809241771698, 97.8006899356842, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(93.82508397102356, 97.82360196113586, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(93.99327039718628, 97.82360196113586, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(93.96924376487732, 97.64032363891602, 96.4102566242218)\n",
      "5 ites of self-training ...\n",
      "(93.96924376487732, 97.84650802612305, 96.92307710647583)\n",
      "5 ites of self-training ...\n",
      "(93.99327039718628, 97.77777791023254, 96.92307710647583)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(87.14157938957214, 98.6254334449768, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(89.7849440574646, 98.05269241333008, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(89.60573673248291, 97.8694200515747, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(89.69534039497375, 97.8006899356842, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(89.56093192100525, 98.00687432289124, 90.76923131942749)\n",
      "5 ites of self-training ...\n",
      "(89.3369197845459, 97.8694200515747, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(89.3369197845459, 97.77777791023254, 90.25641083717346)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.50707030296326, 98.5567033290863, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(94.58058476448059, 97.47995734214783, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.55702304840088, 97.77777791023254, 91.79487228393555)\n",
      "5 ites of self-training ...\n",
      "(94.65126991271973, 97.38832116127014, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.69839930534363, 97.36540913581848, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.69839930534363, 97.2737729549408, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.67483162879944, 97.15922474861145, 92.30769276618958)\n",
      "\n",
      "swin_large_patch4_window12_384_in22k\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(81.07913732528687, 99.56392049789429, 85.12820601463318)\n",
      "5 ites of self-training ...\n",
      "(83.95683765411377, 99.21964406967163, 87.17948794364929)\n",
      "5 ites of self-training ...\n",
      "(84.02878046035767, 99.12784099578857, 87.17948794364929)\n",
      "5 ites of self-training ...\n",
      "(83.98081660270691, 99.28849935531616, 85.6410264968872)\n",
      "5 ites of self-training ...\n",
      "(84.17266011238098, 99.21964406967163, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(83.98081660270691, 99.28849935531616, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(84.02878046035767, 99.12784099578857, 86.66666746139526)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.77945065498352, 99.60982203483582, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.41564679145813, 99.26554560661316, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.55702304840088, 99.19669032096863, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.76908445358276, 99.33440089225769, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.79264616966248, 99.33440089225769, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.86333727836609, 99.21964406967163, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(94.86333727836609, 99.19669032096863, 92.8205132484436)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(88.03763389587402, 99.65572357177734, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(89.4713282585144, 99.40325617790222, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(89.15770649909973, 99.33440089225769, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(89.3369197845459, 99.3803083896637, 86.66666746139526)\n",
      "5 ites of self-training ...\n",
      "(89.6505355834961, 99.3803083896637, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(89.38171863555908, 99.42620992660522, 87.17948794364929)\n",
      "5 ites of self-training ...\n",
      "(89.02329802513123, 99.44915771484375, 87.17948794364929)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(93.0321991443634, 99.81977939605713, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(94.3296492099762, 99.63955879211426, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.16146278381348, 99.66208338737488, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.3296492099762, 99.68461394309998, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.30562257766724, 99.63955879211426, 94.35897469520569)\n",
      "5 ites of self-training ...\n",
      "(94.3296492099762, 99.66208338737488, 94.87179517745972)\n",
      "5 ites of self-training ...\n",
      "(94.25756931304932, 99.66208338737488, 94.35897469520569)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(78.58512997627258, 99.79724884033203, 78.46153974533081)\n",
      "5 ites of self-training ...\n",
      "(80.64748048782349, 99.5043933391571, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(81.00719451904297, 99.54944849014282, 82.56410360336304)\n",
      "5 ites of self-training ...\n",
      "(81.70263767242432, 99.54944849014282, 81.53846263885498)\n",
      "5 ites of self-training ...\n",
      "(81.60671591758728, 99.481862783432, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(81.55875205993652, 99.68461394309998, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(81.55875205993652, 99.63955879211426, 82.05128312110901)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(86.69354915618896, 99.81977939605713, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.70967626571655, 99.68461394309998, 88.20512890815735)\n",
      "5 ites of self-training ...\n",
      "(88.70967626571655, 99.68461394309998, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(88.88888955116272, 99.7071385383606, 89.2307698726654)\n",
      "5 ites of self-training ...\n",
      "(88.93369436264038, 99.61702823638916, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(88.44085931777954, 99.7296690940857, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(88.53046298027039, 99.66208338737488, 88.20512890815735)\n",
      "CORAL alignment ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classifier on labeled ...\n",
      "(93.14326047897339, 99.62916970252991, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.86333727836609, 99.58796501159668, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.02827525138855, 99.5055615901947, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(95.28746604919434, 99.58796501159668, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(95.21677494049072, 99.62916970252991, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(95.26389837265015, 99.62916970252991, 92.8205132484436)\n",
      "5 ites of self-training ...\n",
      "(95.21677494049072, 99.62916970252991, 92.8205132484436)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(79.97602224349976, 99.62916970252991, 82.05128312110901)\n",
      "5 ites of self-training ...\n",
      "(83.3812952041626, 99.62916970252991, 84.10256505012512)\n",
      "5 ites of self-training ...\n",
      "(83.3812952041626, 99.62916970252991, 86.15384697914124)\n",
      "5 ites of self-training ...\n",
      "(83.69304537773132, 99.62916970252991, 85.12820601463318)\n",
      "5 ites of self-training ...\n",
      "(83.54915976524353, 99.62916970252991, 84.61538553237915)\n",
      "5 ites of self-training ...\n",
      "(83.50120186805725, 99.62916970252991, 84.61538553237915)\n",
      "5 ites of self-training ...\n",
      "(83.42925906181335, 99.62916970252991, 84.61538553237915)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.81595349311829, 99.62916970252991, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(93.89716386795044, 99.58796501159668, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(93.75300407409668, 99.58796501159668, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.84911060333252, 99.58796501159668, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(93.96924376487732, 99.58796501159668, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(93.99327039718628, 99.62916970252991, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(94.01729702949524, 99.62916970252991, 95.89743614196777)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(91.56655669212341, 98.64833950996399, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(93.60884428024292, 98.00687432289124, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.58481764793396, 98.09851050376892, 95.38461565971375)\n",
      "5 ites of self-training ...\n",
      "(93.82508397102356, 98.09851050376892, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(93.77703070640564, 98.21305871009827, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(93.8010573387146, 98.21305871009827, 95.89743614196777)\n",
      "5 ites of self-training ...\n",
      "(93.82508397102356, 98.09851050376892, 95.89743614196777)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(87.27598786354065, 98.64833950996399, 87.69230842590332)\n",
      "5 ites of self-training ...\n",
      "(89.24731016159058, 98.19015264511108, 90.25641083717346)\n",
      "5 ites of self-training ...\n",
      "(89.42652344703674, 98.05269241333008, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(89.69534039497375, 98.09851050376892, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(89.60573673248291, 98.19015264511108, 89.74359035491943)\n",
      "5 ites of self-training ...\n",
      "(89.56093192100525, 98.07560443878174, 88.71794939041138)\n",
      "5 ites of self-training ...\n",
      "(89.42652344703674, 98.05269241333008, 88.71794939041138)\n",
      "CORAL alignment ...\n",
      "Train classifier on labeled ...\n",
      "(92.34212636947632, 98.64833950996399, 92.30769276618958)\n",
      "5 ites of self-training ...\n",
      "(94.34495568275452, 97.91523814201355, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.3213939666748, 97.64032363891602, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.36851739883423, 97.70905375480652, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.46277022361755, 97.57159352302551, 93.84615421295166)\n",
      "5 ites of self-training ...\n",
      "(94.36851739883423, 97.50286340713501, 93.33333373069763)\n",
      "5 ites of self-training ...\n",
      "(94.46277022361755, 97.54868745803833, 93.84615421295166)\n",
      "\n",
      "(augmentation, shots):  ('none', 3)\n",
      "================================================================================\n",
      "Results for each ensemble member\n",
      "================================================================================\n",
      "Net, R->C, R->P, R->A, P->R, P->C, P->A, A->P, A->C, A->R, C->R, C->A, C->P, \n",
      "convnext_xlarge_384_in22ft1k, 83.4532380104065, 95.52308917045593, 90.36738276481628, 94.04132962226868, 81.82254433631897, 88.93369436264038, 95.57021856307983, 82.30215907096863, 94.18548941612244, 93.65689754486084, 89.24731016159058, 95.02827525138855, \n",
      "convnext_xlarge_in22ft1k, 84.34053063392639, 95.38171291351318, 89.4713282585144, 93.53676438331604, 82.733815908432, 88.21684718132019, 94.74552273750305, 82.92565941810608, 94.04132962226868, 93.96924376487732, 88.17204236984253, 94.6041464805603, \n",
      "convnext_xlarge_in22k, 83.35731625556946, 95.38171291351318, 88.93369436264038, 93.8010573387146, 82.58993029594421, 87.85842061042786, 94.13289427757263, 83.33333134651184, 94.16146278381348, 93.560791015625, 88.53046298027039, 94.36851739883423, \n",
      "swin_large_patch4_window7_224, 82.68585205078125, 94.72196102142334, 88.30645084381104, 93.9211905002594, 82.32613801956177, 87.6344084739685, 93.68520379066467, 82.78177380561829, 93.560791015625, 93.63287091255188, 88.26164603233337, 93.40245127677917, \n",
      "swin_large_patch4_window7_224_in22k, 83.42925906181335, 95.21677494049072, 88.12723755836487, 94.16146278381348, 81.36690855026245, 87.81362175941467, 94.36851739883423, 82.733815908432, 93.5127317905426, 93.0321991443634, 88.12723755836487, 93.66164207458496, \n",
      "swin_large_patch4_window12_384, 83.95683765411377, 94.55702304840088, 89.24731016159058, 94.23354268074036, 82.18225240707397, 89.11290168762207, 94.93402242660522, 83.42925906181335, 93.3925986289978, 93.99327039718628, 89.3369197845459, 94.67483162879944, \n",
      "swin_large_patch4_window12_384_in22k, 84.02878046035767, 94.86333727836609, 89.02329802513123, 94.25756931304932, 81.55875205993652, 88.53046298027039, 95.21677494049072, 83.42925906181335, 94.01729702949524, 93.82508397102356, 89.42652344703674, 94.46277022361755, \n",
      "\n",
      "================================================================================\n",
      "Simple Majority vote\n",
      "================================================================================\n",
      "R->C, R->P, R->A, P->R, P->C, P->A, A->P, A->C, A->R, C->R, C->A, C->P, \n",
      "85.73141694068909, 95.40528059005737, 90.36738276481628, 94.5699155330658, 83.88489484786987, 89.69534039497375, 95.19321322441101, 84.58033800125122, 94.52186226844788, 94.78616118431091, 90.68100452423096, 95.80584168434143, \n",
      "\n",
      "================================================================================\n",
      "Simple Average (Usually better)\n",
      "================================================================================\n",
      "R->C, R->P, R->A, P->R, P->C, P->A, A->P, A->C, A->R, C->R, C->A, C->P, \n",
      "85.75539588928223, 95.52308917045593, 90.45698642730713, 94.59394812583923, 84.00479555130005, 89.9193525314331, 95.33458948135376, 84.79616045951843, 94.6179747581482, 94.83421444892883, 90.54659605026245, 95.758718252182, \n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Simple Average on Target validation set\n",
      "================================================================================\n",
      "R->C, R->P, R->A, P->R, P->C, P->A, A->P, A->C, A->R, C->R, C->A, C->P, \n",
      "86.66666746139526, 93.33333373069763, 90.76923131942749, 94.87179517745972, 84.10256505012512, 91.79487228393555, 91.79487228393555, 86.66666746139526, 96.4102566242218, 96.92307710647583, 89.74359035491943, 94.87179517745972, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "! python get_results.py --augmentation none --dataset office_home --shots 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b2756e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='office_home', shots=1)\n",
      "================================================================================\n",
      "Ask each 4x7 enasemble members to vote. Majority wins.\n",
      "================================================================================\n",
      "R->C, R->P, R->A, P->R, P->C, P->A, A->P, A->C, A->R, C->R, C->A, C->P, \n",
      "86.13953590393066, 95.17604112625122, 90.38950204849243, 94.66449022293091, 82.95348882675171, 90.17781615257263, 95.3132152557373, 85.09302139282227, 94.33830380439758, 94.31500434875488, 90.93987941741943, 94.65020298957825, \n",
      "\n",
      "================================================================================\n",
      "Average prediction over 4 x 7 models.\n",
      "================================================================================\n",
      "R->C, R->P, R->A, P->R, P->C, P->A, A->P, A->C, A->R, C->R, C->A, C->P, \n",
      "86.16279363632202, 95.22176384925842, 90.43183922767639, 94.71108913421631, 82.86046385765076, 90.38950204849243, 95.19890546798706, 85.37209033966064, 94.38490271568298, 94.33830380439758, 91.06689095497131, 94.67306733131409, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "! python get_results_large.py --dataset office_home --shots 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cb6ec5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['aircraft_carrier', 'alarm_clock', 'ant', 'anvil', 'asparagus', 'axe', 'banana', 'basket', 'bathtub', 'bear', 'bee', 'bird', 'blackberry', 'blueberry', 'bottlecap', 'broccoli', 'bus', 'butterfly', 'cactus', 'cake', 'calculator', 'camel', 'camera', 'candle', 'cannon', 'canoe', 'carrot', 'castle', 'cat', 'ceiling_fan', 'cello', 'cell_phone', 'chair', 'chandelier', 'coffee_cup', 'compass', 'computer', 'cow', 'crab', 'crocodile', 'cruise_ship', 'dog', 'dolphin', 'dragon', 'drums', 'duck', 'dumbbell', 'elephant', 'eyeglasses', 'feather', 'fence', 'fish', 'flamingo', 'flower', 'foot', 'fork', 'frog', 'giraffe', 'goatee', 'grapes', 'guitar', 'hammer', 'helicopter', 'helmet', 'horse', 'kangaroo', 'lantern', 'laptop', 'leaf', 'lion', 'lipstick', 'lobster', 'microphone', 'monkey', 'mosquito', 'mouse', 'mug', 'mushroom', 'onion', 'panda', 'peanut', 'pear', 'peas', 'pencil', 'penguin', 'pig', 'pillow', 'pineapple', 'potato', 'power_outlet', 'purse', 'rabbit', 'raccoon', 'rhinoceros', 'rifle', 'saxophone', 'screwdriver', 'sea_turtle', 'see_saw', 'sheep', 'shoe', 'skateboard', 'snake', 'speedboat', 'spider', 'squirrel', 'strawberry', 'streetlight', 'string_bean', 'submarine', 'swan', 'table', 'teapot', 'teddy-bear', 'television', 'The_Eiffel_Tower', 'The_Great_Wall_of_China', 'tiger', 'toe', 'train', 'truck', 'umbrella', 'vase', 'watermelon', 'whale', 'zebra']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "21646ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'sketch'\n",
    "root = 'data/multi/'\n",
    "image_list_file_path = root + 'unique_image_paths_{}.txt'.format(target)\n",
    "image_paths, labels = make_dataset_fromlist(image_list_file_path)\n",
    "\n",
    "dd = {}\n",
    "for image in image_paths:\n",
    "    label = image.split('/')[1]\n",
    "    assert label in class_list\n",
    "    ind = class_list.index(label)\n",
    "    if not ind in dd:\n",
    "        dd[ind] = [image]\n",
    "    else:\n",
    "        dd[ind].append(image)\n",
    "        \n",
    "labeled_images_filename = root + 'labeled_target_images_{}_3.txt'.format(target)\n",
    "unlabeled_images_filename = root + 'unlabeled_target_images_{}_3.txt'.format(target)\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "labeled_images_file = open(labeled_images_filename, 'w')\n",
    "unlabeled_images_file = open(unlabeled_images_filename, 'w')\n",
    "\n",
    "for ind in range(len(class_list)):\n",
    "    shuffle(dd[ind])\n",
    "    # three labeled\n",
    "    labeled_images = dd[ind][:3]\n",
    "    unlabeled_images = dd[ind][3:]\n",
    "    for image in labeled_images:\n",
    "        labeled_images_file.write(image + ' ' + str(ind) + '\\n')\n",
    "    for image in unlabeled_images:\n",
    "        unlabeled_images_file.write(image + ' ' + str(ind) + '\\n')\n",
    "    \n",
    "labeled_images_file.close()\n",
    "unlabeled_images_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "da175081",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python scramble.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
